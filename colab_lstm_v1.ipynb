{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "really_good_model-no_force-Copy1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PorkPy/LSTM-Force-Predictor/blob/master/colab_lstm_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LMqP2ari4Y_r",
        "colab_type": "code",
        "outputId": "2ea25d70-edd3-47b9-84ca-a5d2392ec2bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "\n",
        "## Imports\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "from torch import nn, optim\n",
        "import random\n",
        "\n",
        "## Set styling parameters for figures\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 14, 10\n",
        "register_matplotlib_converters()\n",
        "\n",
        "## Set random seed for numpy and Torch\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9348cb16d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdoO3HAt4Y_0",
        "colab_type": "text"
      },
      "source": [
        "Check CUDA is available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYOMapqQ4Y_1",
        "colab_type": "code",
        "outputId": "5e5d6cd5-dc55-4689-f261-adbad37242ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7DT2TtE4Y_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CoronaVirusPredictor(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features, n_hidden, seq_len, n_layers=2, ignore_zero=True):\n",
        "        super(CoronaVirusPredictor, self).__init__()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device(\"cuda:0\")\n",
        "            print(\"Running on the GPU\")\n",
        "        else:\n",
        "            device = torch.device(\"cpu\")\n",
        "            print(\"Running on CPU\")\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        self.seq_len = seq_len\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "          input_size=n_features,\n",
        "          hidden_size=n_hidden,\n",
        "          num_layers=n_layers,\n",
        "          dropout=0.5)\n",
        "\n",
        "\n",
        "        self.linear1 = nn.Linear(in_features=n_hidden, out_features=5000)#256\n",
        "        self.linear2 = nn.Linear(in_features=5000, out_features=1)\n",
        "        self.linear3 = nn.Linear(in_features=512, out_features=1024)\n",
        "        self.linear4 = nn.Linear(in_features=1024, out_features=1)\n",
        "\n",
        "        #self.linear5 = nn.Linear(in_features=10000, out_features=10000)\n",
        "        #self.linear6 = nn.Linear(in_features=10000, out_features=1)\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    def reset_hidden_state(self):\n",
        "        self.hidden = (\n",
        "            torch.zeros(self.n_layers, self.seq_len, self.n_hidden).to(device),\n",
        "            torch.zeros(self.n_layers, self.seq_len, self.n_hidden).to(device)\n",
        "        )\n",
        "\n",
        "    def forward(self, sequences):\n",
        "        lstm_out, self.hidden = self.lstm(sequences.view(len(sequences), self.seq_len, -1),self.hidden)\n",
        "        last_time_step = lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n",
        "        y_pred = self.linear1(last_time_step)\n",
        "        y_pred = self.linear2(y_pred)\n",
        "        #y_pred = self.linear3(y_pred)\n",
        "        #y_pred = self.linear4(y_pred)\n",
        "        #y_pred = self.linear5(y_pred)\n",
        "        #y_pred = self.linear6(y_pred)\n",
        "\n",
        "\n",
        "\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba0_Bapk4ZAD",
        "colab_type": "code",
        "outputId": "1e900155-a33a-43bd-bc71-31924a626814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on CPU\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezMpPquf4ZAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model):\n",
        "   \n",
        "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)#0.0007\n",
        "        \n",
        "    num_epochs =600 #600\n",
        "\n",
        "    train_hist = np.zeros(num_epochs)\n",
        "    test_hist = np.zeros(num_epochs)\n",
        "    \n",
        "              \n",
        "    model = model.to(device)\n",
        "    \n",
        "    #for i in range(1): #1\n",
        "        \n",
        "#         for j in range(len(batches)): \n",
        "#             print(\"\\n Epoch:\", i, \"Batch num:\", j, '\\n')\n",
        "#             train_data, train_labels, test_data, test_labels = get_batches(j)       \n",
        "\n",
        "\n",
        "    for t in range(num_epochs):\n",
        "\n",
        "\n",
        "        for j in range(len(batches)):\n",
        "            \n",
        "            \n",
        "            train_data, train_labels, test_data, test_labels = get_batches(j)\n",
        "\n",
        "\n",
        "            if t % 100 == 0:\n",
        "                model.reset_hidden_state() # Requiered because he hiddent state was forgetting too early. \n",
        "\n",
        "            y_pred = model(train_data)\n",
        "\n",
        "            loss = loss_fn(y_pred.float(), train_labels)\n",
        "\n",
        "\n",
        "            if test_data is not None:\n",
        "                with torch.no_grad():\n",
        "                    y_test_pred = model(train_data)\n",
        "                    test_loss = loss_fn(y_test_pred.float(), train_labels)\n",
        "                test_hist[t] = test_loss.item()\n",
        "\n",
        "                if t % 10 == 0:  \n",
        "                    print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n",
        "            elif t % 10 == 0:\n",
        "                  print(f'Epoch {t} train loss: {loss.item()}')\n",
        "\n",
        "            train_hist[t] = loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return model.eval(), train_hist, test_hist, optimizer, t, loss_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWk7KJfm4ZAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/PorkPy/LSTM-Force-Predictor/master/80k_data/mean_force_data.csv'\n",
        "\n",
        "data = pd.read_csv(url)\n",
        "#data = data[:80000]\n",
        "main_seq = data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "zL86i1VC4ZAQ",
        "colab_type": "code",
        "outputId": "c6d85173-ebe8-4361-dfb8-7277addde941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "n=1000\n",
        "batchesx = [data[i:i + n] for i in range(0, len(data), n)]\n",
        "print(len(batchesx))\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(batchesx)\n",
        "\n",
        "########################\n",
        "high_force_list = []\n",
        "sub_list = [4,6,7,13,17,20]#,21,29,40,49,57,62,66,70,72,73,74]\n",
        "for i in sub_list:\n",
        "    high_force_list.append(batchesx[i])\n",
        "\n",
        "\n",
        "\n",
        "batches = high_force_list#[:20]\n",
        "val_batches = high_force_list#[20:40]\n",
        "test_batches = high_force_list#[:20]\n",
        "print(len(batches), len(val_batches), len(test_batches))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79\n",
            "6 6 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPoDlRZk4ZAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuctksCy4ZAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(len(high_force_list))\n",
        "#print(high_force_list[8])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmYXrscp4ZAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(test_batches[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr2E1Y3k4ZAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_batch(batch_number):\n",
        "    \n",
        "    seq_size = 500\n",
        "\n",
        "    X_test = []\n",
        "    \n",
        "    data = test_batches[batch_number].reset_index(drop=True)\n",
        "    data= data[:seq_size]\n",
        "\n",
        "    features = data[['joint_0', 'joint_2', 'joint_4', 'joint_5']]\n",
        "    features = np.asarray(features)\n",
        "\n",
        "    targets = data.iloc[:,-1]\n",
        "    targets = np.asarray(targets)\n",
        "    targets = targets.reshape(-1,1)\n",
        "    \n",
        "    for i in range(len(features)):           \n",
        "   \n",
        "        X =(features[:i+1])\n",
        "        an_array = np.array(X)\n",
        "        shape = np.shape(X)\n",
        "        temp = np.zeros((seq_size, 4))\n",
        "        temp[(seq_size-shape[0]):,:shape[1]] = an_array\n",
        "        X_test.append(temp)\n",
        "        y_test = targets\n",
        "\n",
        "    \n",
        "    X_test = torch.cuda.FloatTensor(X_test)\n",
        "    y_test = torch.cuda.FloatTensor(y_test)\n",
        "    # print(data, '\\n')\n",
        "    # print( X_test.shape, y_test.shape)\n",
        "    jim = targets\n",
        "    return(X_test, y_test, jim)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFM4HB024ZAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(get_test_batch(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBdi2i8x4ZAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(batch_num):  \n",
        "    \n",
        "    seq_size = 500\n",
        "\n",
        "    data = batches[batch_num].reset_index(drop=True)\n",
        "    data= data[:seq_size]\n",
        "    ################################################\n",
        "\n",
        "    X_train = []\n",
        "    X_test = []\n",
        "\n",
        "    \n",
        "    features = data[['joint_0', 'joint_2', 'joint_4', 'joint_5']]\n",
        "    features = np.asarray(features)\n",
        "\n",
        "    targets = data.iloc[:,-1]\n",
        "    targets = np.asarray(targets)\n",
        "    targets = targets.reshape(-1,1)\n",
        "\n",
        "\n",
        "    for i in range(len(features)):           \n",
        "        \n",
        "        #np.random.seed(42)\n",
        "       \n",
        "        X =(features[:i+1])\n",
        "        an_array = np.array(X)\n",
        "        shape = np.shape(X)\n",
        "        temp = np.zeros((seq_size, 4))\n",
        "        temp[(seq_size-shape[0]):,:shape[1]] = an_array\n",
        "        X_train.append(temp)\n",
        "        y_train = targets\n",
        "    \n",
        "    data = val_batches[batch_num].reset_index(drop=True)\n",
        "    data= data[:seq_size]\n",
        "\n",
        "    features = data[['joint_0', 'joint_2', 'joint_4', 'joint_5']]\n",
        "    features = np.asarray(features)\n",
        "\n",
        "    targets = data.iloc[:,-1]\n",
        "    targets = np.asarray(targets)\n",
        "    targets = targets.reshape(-1,1)\n",
        "    \n",
        "    for i in range(len(features)):           \n",
        "   \n",
        "        X =(features[:i+1])\n",
        "        an_array = np.array(X)\n",
        "        shape = np.shape(X)\n",
        "        temp = np.zeros((seq_size, 4))\n",
        "        temp[(seq_size-shape[0]):,:shape[1]] = an_array\n",
        "        X_test.append(temp)\n",
        "        y_test = targets\n",
        "\n",
        "    \n",
        "\n",
        "    X_train = torch.cuda.FloatTensor(X_train) # Change data to tensors\n",
        "    y_train = torch.cuda.FloatTensor(y_train)\n",
        "    X_test = torch.cuda.FloatTensor(X_test)\n",
        "    y_test = torch.cuda.FloatTensor(y_test)\n",
        "    \n",
        "    #del targets, features, data, temp, an_array\n",
        "    \n",
        "    #print(data)\n",
        "    #print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "    return(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xzhuCdB4ZA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(get_batches(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EjQYm7AR4ZA9",
        "colab_type": "code",
        "outputId": "b6948bfe-ebce-484a-f6d2-d4c5d2ab3da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "seq_length = 500 # when using zero padding, this seq_length is a bit redundent but still has to match the zero's size.\n",
        "\n",
        "model = CoronaVirusPredictor(\n",
        "      n_features=4, \n",
        "      n_hidden=64, \n",
        "      seq_len=seq_length, \n",
        "      n_layers=2\n",
        "    )\n",
        "\n",
        "model, train_hist, test_hist, optimizer, epochs, loss = train_model(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n",
            "Epoch 0 train loss: 119.65691375732422 test loss: 119.6642837524414\n",
            "Epoch 0 train loss: 217.49432373046875 test loss: 217.4732208251953\n",
            "Epoch 0 train loss: 294.4775085449219 test loss: 294.47076416015625\n",
            "Epoch 0 train loss: 193.48678588867188 test loss: 193.43479919433594\n",
            "Epoch 0 train loss: 311.1365051269531 test loss: 311.113525390625\n",
            "Epoch 0 train loss: 489.18365478515625 test loss: 489.12701416015625\n",
            "Epoch 10 train loss: 45.79402542114258 test loss: 45.09754943847656\n",
            "Epoch 10 train loss: 81.16183471679688 test loss: 80.32794189453125\n",
            "Epoch 10 train loss: 131.15452575683594 test loss: 130.1009521484375\n",
            "Epoch 10 train loss: 12.431268692016602 test loss: 11.885086059570312\n",
            "Epoch 10 train loss: 40.052032470703125 test loss: 39.95691680908203\n",
            "Epoch 10 train loss: 228.9415740966797 test loss: 229.8750762939453\n",
            "Epoch 20 train loss: 44.75189208984375 test loss: 44.39842224121094\n",
            "Epoch 20 train loss: 81.89891815185547 test loss: 82.40676879882812\n",
            "Epoch 20 train loss: 127.39762115478516 test loss: 129.2009735107422\n",
            "Epoch 20 train loss: 12.031338691711426 test loss: 11.983840942382812\n",
            "Epoch 20 train loss: 36.748619079589844 test loss: 36.70594024658203\n",
            "Epoch 20 train loss: 227.83416748046875 test loss: 226.3600311279297\n",
            "Epoch 30 train loss: 44.84955978393555 test loss: 43.81935501098633\n",
            "Epoch 30 train loss: 82.60480499267578 test loss: 83.16328430175781\n",
            "Epoch 30 train loss: 124.22021484375 test loss: 123.72775268554688\n",
            "Epoch 30 train loss: 11.841852188110352 test loss: 12.058927536010742\n",
            "Epoch 30 train loss: 35.912742614746094 test loss: 36.387855529785156\n",
            "Epoch 30 train loss: 227.80596923828125 test loss: 229.09332275390625\n",
            "Epoch 40 train loss: 44.49284744262695 test loss: 43.4027099609375\n",
            "Epoch 40 train loss: 83.2313461303711 test loss: 83.95657348632812\n",
            "Epoch 40 train loss: 118.29645538330078 test loss: 117.63184356689453\n",
            "Epoch 40 train loss: 12.168570518493652 test loss: 11.824775695800781\n",
            "Epoch 40 train loss: 35.423805236816406 test loss: 35.82482147216797\n",
            "Epoch 40 train loss: 229.53439331054688 test loss: 229.60585021972656\n",
            "Epoch 50 train loss: 39.98737716674805 test loss: 40.24422073364258\n",
            "Epoch 50 train loss: 88.43439483642578 test loss: 87.89588165283203\n",
            "Epoch 50 train loss: 99.58954620361328 test loss: 100.3828353881836\n",
            "Epoch 50 train loss: 12.115364074707031 test loss: 12.18751049041748\n",
            "Epoch 50 train loss: 33.97184753417969 test loss: 34.14845657348633\n",
            "Epoch 50 train loss: 235.5851287841797 test loss: 236.65931701660156\n",
            "Epoch 60 train loss: 29.627859115600586 test loss: 28.900836944580078\n",
            "Epoch 60 train loss: 83.65882110595703 test loss: 84.14492797851562\n",
            "Epoch 60 train loss: 66.41056823730469 test loss: 64.87638092041016\n",
            "Epoch 60 train loss: 12.586199760437012 test loss: 12.478484153747559\n",
            "Epoch 60 train loss: 34.06988525390625 test loss: 34.1501579284668\n",
            "Epoch 60 train loss: 231.46353149414062 test loss: 230.1149139404297\n",
            "Epoch 70 train loss: 63.98160934448242 test loss: 63.54893112182617\n",
            "Epoch 70 train loss: 96.52352905273438 test loss: 96.1574478149414\n",
            "Epoch 70 train loss: 122.5684585571289 test loss: 122.95650482177734\n",
            "Epoch 70 train loss: 14.26352596282959 test loss: 14.036428451538086\n",
            "Epoch 70 train loss: 25.39437484741211 test loss: 25.865570068359375\n",
            "Epoch 70 train loss: 216.45687866210938 test loss: 215.0589141845703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "m25VPaNo4ZBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_hist, label=\"Training loss\")\n",
        "plt.plot(test_hist, label=\"Test loss\")\n",
        "#plt.ylim((0, 5))\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUYlpGz44ZBF",
        "colab_type": "text"
      },
      "source": [
        "RL Controller Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA-ZdJRy4ZBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(Xtest[0].shape)\n",
        "# print(Xtest[0])\n",
        "# seq = Xtest[22].reshape(-1,500,4) #For a given move,\n",
        "# pred = model(seq).to(device) # send to model and get force prediction.\n",
        "# print(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pym0ZY8g4ZBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Xtest, ytest, jim = get_test_batch(0)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    \n",
        "\n",
        "    test_seq = Xtest[0].reshape(-1,500,4)#.reshape(1,200,4) # input first sequence from trajectory/batch\n",
        "    preds = [] # create a list to store predictions.\n",
        "    for i in range(len(Xtest)-1): # for each sequence i in the trajectory,\n",
        "        y_test_pred = model(test_seq).to(device) # send sequence to model,\n",
        "        pred = torch.flatten(y_test_pred).item() # reshape the model output,\n",
        "        \n",
        "        preds.append(pred) # and append to the list of predictions - preds.\n",
        "        new_seq = Xtest[i+1].reshape(-1,500,4)#.reshape(1,200,4) # Change sequence to the next one in the list.\n",
        "        #print(test_seq, pred, '\\n')\n",
        "        test_seq = torch.cuda.FloatTensor(new_seq).view(1, seq_length, -1) # change sequence to a torch Tensor\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9j5z-564ZBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(Xtest[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "trCkG3Kp4ZBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = np.asarray(preds)\n",
        "preds = np.reshape(preds, (-1,1))\n",
        "\n",
        "ytest2 = ytest.cpu()\n",
        "ytest2 = np.asarray(ytest2)\n",
        "ytest2 = np.reshape(ytest2, (-1,1))\n",
        "\n",
        "predicted_cases = preds\n",
        "true_cases = ytest2\n",
        "\n",
        "\n",
        "preds = np.asarray(preds)\n",
        "preds = np.reshape(preds, (-1,1))\n",
        "\n",
        "ytest2 = ytest.cpu()\n",
        "ytest2 = np.asarray(ytest2)\n",
        "ytest2 = np.reshape(ytest2, (-1,1))\n",
        "\n",
        "predicted_cases = preds\n",
        "true_cases = ytest2\n",
        "\n",
        "\n",
        "print(main_seq.shape)\n",
        "seq = pd.DataFrame(jim)\n",
        "seq = seq.reset_index(drop=True)\n",
        "main_seq_reset = main_seq.reset_index(drop=True)\n",
        "\n",
        "plt.plot(seq,label='Sequence')\n",
        "\n",
        "print(len(predicted_cases))\n",
        "plt.plot( true_cases[:,-1], label='Real Force')\n",
        "\n",
        "plt.plot(predicted_cases[:,-1], label='Predicted Force')\n",
        "\n",
        "\n",
        "\n",
        "#bob = (test_batches[79].reset_index(drop=True))\n",
        "#print(bob.shape)\n",
        "#plt.plot(bob.iloc[:500,-1])\n",
        "plt.legend();\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5PPy38x4ZBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(batches[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iZX9L8P4ZBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "scaler = scaler.fit(data)\n",
        "\n",
        "all_data = scaler.transform(data)\n",
        "\n",
        "all_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtZ23soJ4ZBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tX_all, y_all = train_create_sequences( seq_length)\n",
        "\n",
        "X_all = torch.cuda.FloatTensor(X_all)\n",
        "y_all = torch.cuda.FloatTensor(y_all)\n",
        "\n",
        "model = CoronaVirusPredictor(\n",
        "  n_features=7, \n",
        "  n_hidden=512, \n",
        "  seq_len=seq_length, \n",
        "  n_layers=2\n",
        ")\n",
        "model, train_hist, _ = train_model(model, X_all, y_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGAEgilt4ZBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DAYS_TO_PREDICT = 5\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_seq = X_all[:1]\n",
        "    preds = []\n",
        "    for _ in range(DAYS_TO_PREDICT):\n",
        "    \n",
        "        y_test_pred = model(test_seq).to(device)\n",
        "        pred = torch.flatten(y_test_pred).item()\n",
        "        preds.append(pred)\n",
        "        print(pred)\n",
        "        new_seq = test_seq.cpu().numpy().flatten()\n",
        "        new_seq = np.append(new_seq, [pred])\n",
        "        new_seq = new_seq[1:]\n",
        "        test_seq = torch.cuda.FloatTensor(new_seq).view(1, seq_length, -1)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuB4MRkA4ZBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_cases = scaler.inverse_transform(preds).flatten()\n",
        "print(predicted_cases.shape)\n",
        "                                           \n",
        "# print(np.shape(preds))\n",
        "# preds = np.asarray(preds)\n",
        "# preds = preds.reshape([5,7])\n",
        "# print(np.shape(preds))\n",
        "\n",
        "# predicted_cases = scaler.inverse_transform(preds)                                           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNuQ6EMD4ZBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(daily_cases, label='Historical Daily Cases')\n",
        "plt.plot(predicted_cases, label='Predicted Daily Cases')\n",
        "plt.legend();\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}