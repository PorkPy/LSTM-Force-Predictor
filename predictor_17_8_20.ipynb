{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predictor_17_8_20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBgEk5Qbm4jTgHEyem2Q6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PorkPy/LSTM-Force-Predictor/blob/master/predictor_17_8_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny4Wo1tCDMuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee2d2fe0-d86f-4818-c005-aa5abf021072"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyg5AR5VDILK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% reset -f\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import matplotlib.ticker as plticker\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import norm\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "from subprocess import call\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsmubMuYDDOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54a6f6ba-38d3-4ba4-9b58-6db4b5898fad"
      },
      "source": [
        "'''              ### MODEL HYPER-PARAMETER SETTINGS ###\n",
        "-------------------------------------------------------------------------------\n",
        "Here, the model hyper-parameters can be set, along with the save model path \n",
        "and the warm start model parameters path if using a pretrained model. \n",
        "'''\n",
        "model_num  = '1001'        ## Unique model number for saving new model.\n",
        "model_dir  = 'model1001'   ## New directory name to save new model to. \n",
        "params     = '1000_v92'     ## Pretrained model params to load...\n",
        "warm_start = True        ## ...and if to load them or not.\n",
        "seq_length = 1000          ## The length of the trajectory slice trained on.\n",
        "epochs     = 101          ## Number of full passes through the whole dataset.\n",
        "hidden     = 64           ## Number of nodes in the LSTM layers.\n",
        "lstm_layers = 2\n",
        "lr         = 0.0005       ## Learning rate.\n",
        "feature_num   =  6        ## 4 features for joint data, 6 features for cartesian data.\n",
        "fc         = 1           ## Number of fully connected layers. 1 or 2.\n",
        "dropout = 0.5\n",
        "random_seed = 42           ## Used to seed the random number generator for reproducibility.\n",
        "\n",
        "## Remarks about this particular test.\n",
        "notes = (\"\"\"  \n",
        "            \n",
        "\"\"\")\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(42) ## We should keep the same torch seed for the same weight initialisation.\n",
        "path       = f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/\" ## Save directory.\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "## I increased the batch size and lr by 1 order.\n",
        "\n",
        "## Functions to fetch hyper-parameters\n",
        "def model_number():\n",
        "    return model_num\n",
        "\n",
        "def load_params():\n",
        "    return params\n",
        "\n",
        "def model_directory():\n",
        "    return model_dir\n",
        "\n",
        "def get_seq_length():\n",
        "    return seq_length\n",
        "\n",
        "def get_epochs():\n",
        "    return epochs\n",
        "\n",
        "def get_warm_start():\n",
        "    return warm_start\n",
        "\n",
        "def get_hidden():\n",
        "    return hidden\n",
        "\n",
        "def get_lr():\n",
        "    return lr\n",
        "\n",
        "def get_path():\n",
        "    return path\n",
        "\n",
        "def get_features():\n",
        "    return feature_num\n",
        "\n",
        "def get_fc():\n",
        "    return fc\n",
        "\n",
        "def get_lstm_layers():\n",
        "    return lstm_layers\n",
        "\n",
        "def get_random_seed():\n",
        "    return random_seed\n",
        "\n",
        "def get_dropout():\n",
        "    return dropout\n",
        "\n",
        "## Dictionary with which to save paramers.\n",
        "param = {'Model Num':model_num, \n",
        "          'Seq Length': seq_length,\n",
        "          'Epochs': epochs,\n",
        "          'Warm Start': (warm_start),\n",
        "          'Pretrained on': params,\n",
        "          'Hidden Size': hidden,\n",
        "          'Learning Rate': lr,\n",
        "          'features': feature_num, \n",
        "          'Num LSTM Layers':lstm_layers,\n",
        "          'Num FC Layers':fc,\n",
        "          'Dropout': dropout,\n",
        "          'Random Seed': random_seed,\n",
        "          'Data/Notes': notes\n",
        "}\n",
        "\n",
        "## Create new directory in perent directory to save parameters.\n",
        "try:\n",
        "    os.makedirs(path)\n",
        "except OSError:\n",
        "    print (\"Creation of the directory %s failed\" % path)\n",
        "else:\n",
        "    print (\"Successfully created the directory %s \" % path)\n",
        "\n",
        "\n",
        "## create a pandas data frame of the model parameters and save to csv.\n",
        "param = pd.DataFrame(param, index=[0])\n",
        "param.to_csv(path + \"lstm_params.csv\", index=False)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the directory /content/drive/My Drive/PhD/PhD/lstm/model1001/ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFxQcSATFwbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ForcePredictor(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features, n_hidden, seq_len, n_layers=2, ignore_zero=True):\n",
        "        super(ForcePredictor, self).__init__()\n",
        "        dropout = get_dropout()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device(\"cuda:0\")\n",
        "            print(\"Running on the GPU\")\n",
        "        else:\n",
        "            device = torch.device(\"cpu\")\n",
        "            print(\"Running on CPU\")\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        self.seq_len = seq_len\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "          input_size=n_features,\n",
        "          hidden_size=n_hidden,\n",
        "          num_layers=n_layers)#,\n",
        "          #dropout= dropout)\n",
        "        \n",
        "        \n",
        "        fc = get_fc() ## get num of FC layers\n",
        "\n",
        "\n",
        "        if fc == 1:\n",
        "            self.linear1 = nn.Linear(in_features=n_hidden, out_features=3)\n",
        "            \n",
        "        elif fc == 2:\n",
        "            self.linear1 = nn.Linear(in_features=n_hidden, out_features=60)\n",
        "            self.linear2 = nn.Linear(in_features=60, out_features=3)\n",
        "\n",
        "        elif fc == 3:\n",
        "            self.linear1 = nn.Linear(in_features=n_hidden, out_features=60)\n",
        "            self.linear2 = nn.Linear(in_features=60, out_features=60)\n",
        "            self.linear3 = nn.Linear(in_features=60, out_features=3)\n",
        "        \n",
        "    def reset_hidden_state(self):\n",
        "        self.hidden = (\n",
        "            torch.zeros(self.n_layers, self.seq_len, self.n_hidden).to(device),\n",
        "            torch.zeros(self.n_layers, self.seq_len, self.n_hidden).to(device)\n",
        "        )\n",
        "\n",
        "    ## Forward Function.\n",
        "    \n",
        "    def forward(self, sequences):\n",
        "\n",
        "        '''                    ## Forward Method ##\n",
        "        -----------------------------------------------------------------------\n",
        "        This Method takes the input and passes it through each of the network \n",
        "        layers.\n",
        "        The number of fully connected layers the input gets passed through is\n",
        "        dependent on the number stipulated in the network hyper-parameters at\n",
        "        the beginning of the notebook.\n",
        "        ----------------------------------------------------------------------- \n",
        "        '''\n",
        "        \n",
        "        fc = get_fc() ## get num of FC layers\n",
        "\n",
        "        lstm_out, self.hidden = self.lstm(sequences.view(len(sequences), self.seq_len, -1),self.hidden)\n",
        "        last_time_step = lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n",
        "\n",
        "        if fc == 1:\n",
        "            y_pred = self.linear1(last_time_step)\n",
        "\n",
        "        if fc == 2:\n",
        "            y_pred = F.leaky_relu(self.linear1(last_time_step))\n",
        "            y_pred = self.linear2(y_pred)\n",
        "\n",
        "        if fc == 3:\n",
        "            y_pred = F.leaky_relu(self.linear1(last_time_step))\n",
        "            y_pred = F.leaky_relu(self.linear2(y_pred))\n",
        "            y_pred = self.linear3(y_pred)\n",
        "\n",
        "       \n",
        "\n",
        "        return y_pred"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYy0lTD1DAC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4b2044db-23b6-48c1-ae21-23fffed1cef3"
      },
      "source": [
        "model = ForcePredictor(\n",
        "      n_features=get_features(), \n",
        "      n_hidden= get_hidden(), #32, #64\n",
        "      seq_len=seq_length, \n",
        "      n_layers=lstm_layers\n",
        "    )\n",
        "\n",
        "\n",
        "lr = get_lr()\n",
        "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
        "device = torch.device(\"cuda:0\")\n",
        "loss_fn = loss_fn.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)#0.0007 \n",
        "print(\"learning rate =\", lr) \n",
        "num_epochs = get_epochs() #1600 #600\n",
        "path = get_path()\n",
        "seq_length = get_seq_length()\n",
        "\n",
        "#--------------------------------------------------------------------------\n",
        "'''                   ## Get Model Parameters ##\n",
        "---------------------------------------------------------------------------\n",
        "If you want to restart training from an earlier model, first - it should be\n",
        "stipulated in the hyper-parameter setting at the beginning of the notebook\n",
        "by setting 'warm_start' = true, and adding the path to the saved model \n",
        "location.\n",
        "\n",
        "\n",
        "'''\n",
        "start_epoch = 0\n",
        "warm_start = get_warm_start()\n",
        "if warm_start == True:      \n",
        "    params = load_params() # model num and version num: 4_v100.\n",
        "    PATH = f\"/content/drive/My Drive/PhD/PhD/lstm/model_params{params}.pt\"     \n",
        "    checkpoint = torch.load(PATH)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    for state in optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.cuda()\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    loss_fn = checkpoint['loss']\n",
        "    loss_fn = loss_fn.to(device)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "def lighten_color(color, amount=0.5):\n",
        "    import matplotlib.colors as mc\n",
        "    import colorsys\n",
        "    try:\n",
        "        c = mc.cnames[color]\n",
        "    except:\n",
        "        c = color\n",
        "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
        "    return colorsys.hls_to_rgb(c[0], max(0, min(1, amount * c[1])), c[2])\n",
        "\n",
        "def tests(model_name):\n",
        "    \n",
        "    ## fetch parameters\n",
        "    seq_len = get_seq_length()\n",
        "    model_name = model_name\n",
        "    model_dir = model_directory()\n",
        "    path = get_path()\n",
        "    features_num = get_features()\n",
        "\n",
        "    \n",
        "    ## Create new directory in perent directory\n",
        "    path = path + f\"{model_name}/\"\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % path)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % path)\n",
        "\n",
        "    stats_list = []\n",
        "    pdf = PdfPages(path + f\"testing_traj_pics_{model_name}.pdf\")\n",
        "    fig = plt.figure()\n",
        "\n",
        "    \n",
        "    #model = model.to(device)\n",
        "    #print(model)\n",
        "    #print(\"testing weights\", model.linear1.weight.data) # Check weights are being updated.\n",
        "\n",
        "    #model.reset_hidden_state()\n",
        "    for traj in range(len(test_batches)):\n",
        "        model.reset_hidden_state()\n",
        "        whole_traj = []\n",
        "        whole_true = []\n",
        "\n",
        "        '''Although it is possible to feed in the entire trajectory and get\n",
        "        the same prediction results, this cannot be done within the same model \n",
        "        instance, as the sequence length is fixed. \n",
        "        '''\n",
        "        for start_seq in range(int(1000/seq_length)): \n",
        "            start_seqx = start_seq*seq_length ## get the next sequence start position\n",
        "            #model.reset_hidden_state()\n",
        "\n",
        "            Xtest, ytest = get_test_batch(traj, start_seqx)\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                \n",
        "                x = iter(Xtest)\n",
        "                test_seq = Xtest[0].reshape(-1,seq_len,features_num)#.reshape(1,200,4) # input first sequence from trajectory/batch\n",
        "                preds = [] # create a list to store predictions.\n",
        "                for i in range(len(Xtest)): # for each sequence i in the trajectory,\n",
        "                    y_test_pred = model(test_seq).to(device)# send sequence to model,\n",
        "                    pred = torch.flatten(y_test_pred).cpu() # reshape the model output,\n",
        "                    preds.append(np.asarray(pred)) # and append to the list of predictions - preds.\n",
        "                    new_seq = next(x).reshape(-1,seq_len,features_num)#.reshape(1,200,4) # Change sequence to the next one in the list.\n",
        "                    test_seq = torch.cuda.FloatTensor(new_seq).view(1, seq_len, -1) # change sequence to a torch Tensor\n",
        "            whole_traj.append(preds)\n",
        "            whole_true.append(ytest)\n",
        "        whole_true = np.array(whole_true).reshape(-1,)\n",
        "        ## rescale the output predictions\n",
        "        preds = target_scaler.inverse_transform(whole_traj).reshape(-1,3)\n",
        "        ## Vector summation - the vector sum of the 3 output predictions\n",
        "        force_vec = np.sqrt((preds[:,0]**2)+(preds[:,1]**2)+(preds[:,2]**2))\n",
        "        \n",
        "        ytest = whole_true\n",
        "        preds = force_vec ## reset name to comply with existing code.\n",
        "        #display(force_vec)\n",
        "        \n",
        "        #Mean Absolute Error\n",
        "        MAE_list = []\n",
        "        for i,j in zip(preds, ytest):\n",
        "            error = np.abs(i-j)\n",
        "            MAE_list.append(error)\n",
        "        MAE = float(\"{:.3f}\".format(np.mean(MAE_list)))\n",
        "        #print(\"MAE\",\"{:.3f}\".format(MAE),'N')\n",
        "\n",
        "        # Coefficient of Variance\n",
        "        mean = np.mean(data.iloc[:,-1]) # mean of all dependent variables.\n",
        "        cov_list = []\n",
        "        for i,j in zip(preds, ytest):\n",
        "            sq_dev = (i-j)**2\n",
        "            cov_list.append(sq_dev)    \n",
        "        MSD = np.mean(cov_list) # mean square deviation\n",
        "        RMSD = np.sqrt(MSD) # root mean square deviation\n",
        "        cov = RMSD/mean # coefficient of variance\n",
        "        RMSD = float(\"{:.3f}\".format(RMSD))\n",
        "        cov =  float(\"{:.3f}\".format(cov))\n",
        "        #print(\"COV:\",\"{:.3f}\".format(cov))\n",
        "        \n",
        "    \n",
        "        my_dict = {'Trajectory':traj,\n",
        "                'MAE': MAE, \n",
        "                'RMSD':RMSD,\n",
        "                'cov': cov, # Used to normalise the RMSD accross all the data\n",
        "        }\n",
        "        stats_list.append(my_dict)\n",
        "\n",
        "        # Plot forces\n",
        "        predicted_cases = preds\n",
        "        true_cases = ytest\n",
        "        # Add title and axis names\n",
        "        plt.title(f'Force Trajectory {traj}');\n",
        "        plt.xlabel('Sample num');\n",
        "        plt.ylabel('Force (N)');\n",
        "        plt.tight_layout();\n",
        "        plt.grid(True)\n",
        "        plt.ylim(-1, 70)\n",
        "        plt.plot(true_cases, color=lighten_color('b', 1.7), linewidth=3.0, label='Real Force');\n",
        "        x = [i for i in range(1000)]\n",
        "        #plt.scatter(x, predicted_cases, marker='.', s=1, c='r', label='Predicted Force');\n",
        "        plt.legend(loc=2, prop={'size': 6})\n",
        "\n",
        "        from numpy.polynomial import Polynomial\n",
        "        x = [i for i in range(1000)]\n",
        "        y = predicted_cases\n",
        "        \n",
        "        p = Polynomial.fit(x, y, 50)\n",
        "        plt.plot(*p.linspace(), color=lighten_color('r', 1.0), linewidth=1.0, label='Real Force');\n",
        "\n",
        "\n",
        "        # save the current figure\n",
        "        pdf.savefig(fig);\n",
        "        # destroy the current figure\n",
        "        plt.clf()\n",
        "\n",
        "    pdf.close()\n",
        "    stats_list = pd.DataFrame(stats_list)\n",
        "    return stats_list\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "def stats(stats_list2, model_name):\n",
        "    \n",
        " \n",
        "    ## Get the mean of MAE, RMSD and cov.\n",
        "    mean_list = {\n",
        "                'MAE' :float(\"{:.3f}\".format(np.mean(stats_list2['MAE']))),\n",
        "                'RMSD':float(\"{:.3f}\".format(np.mean(stats_list2['RMSD']))),\n",
        "                'cov' :float(\"{:.3f}\".format(np.mean(stats_list2['cov'])))\n",
        "    }\n",
        "    ## Get the std-dev of MAE, RMSD and cov.\n",
        "    std_dev = {\n",
        "                'MAE' :float(\"{:.3f}\".format(np.std(stats_list2['MAE']))),\n",
        "                'RMSD':float(\"{:.3f}\".format(np.std(stats_list2['RMSD']))),\n",
        "                'cov' :float(\"{:.3f}\".format(np.std(stats_list2['cov'])))\n",
        "    }\n",
        "    ## Get the max value of MAE, RMSD and cov.\n",
        "    max_list = {\n",
        "                'MAE' :float(stats_list2['MAE'].max()),\n",
        "                'RMSD':float(stats_list2['RMSD'].max()),\n",
        "                'cov' :float(stats_list2['cov'].max())\n",
        "    }\n",
        "    ## append above dicts to stats_list2.\n",
        "    stats_list2 = stats_list2.append(mean_list, ignore_index=True).fillna('Grand Mean')\n",
        "    stats_list2 = stats_list2.append(std_dev, ignore_index=True).fillna('Standard Dev')\n",
        "    stats_list2 = stats_list2.append(max_list, ignore_index=True).fillna('Max Value')\n",
        "\n",
        "    #display(stats_list2)\n",
        "    path = get_path()\n",
        "    \n",
        "    ## Create new directory in perent directory\n",
        "    path = path + f\"{model_name}/\"\n",
        "    model_name = model_name\n",
        "\n",
        "    ## save stats_list as .csv in same directory as trajectory plots.\n",
        "    stats_list2.to_csv(path + f\"lstm_model_metrics_{model_name}.csv\", index=False)\n",
        "    return stats_list2\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "## Get a Gaussian Distribution of the MAE, RMSD and cov.\n",
        "def gauss_plot(stats_list2, name, error_type, num):\n",
        "    model_name = name\n",
        "    model_dir = model_directory()\n",
        "    path = get_path()\n",
        "    path = path + f\"{model_name}/\"\n",
        "\n",
        "    error = error_type ## Either; MAE, RMSD or cov.\n",
        "    pdf = PdfPages(path + f\"gauss_pic_{error}.pdf\")\n",
        "    fig = plt.figure()\n",
        "    \n",
        "    # define constants\n",
        "    mu = np.mean(stats_list2.iloc[:-3,num]) \n",
        "    sigma = np.sqrt(np.var(stats_list2.iloc[:-3,num]))\n",
        "    x1 = np.min(stats_list2.iloc[:-3,num])\n",
        "    x2 = np.max(stats_list2.iloc[:-3,num])\n",
        "    \n",
        "\n",
        "    # calculate the z-transform\n",
        "    z1 = ( x1 - mu ) / sigma\n",
        "    z2 = ( x2 - mu ) / sigma\n",
        "\n",
        "    x = np.arange(z1, z2, 0.001) # range of x in spec\n",
        "    x_all = np.arange(-10, 10, 0.001) # entire range of x, both in and out of spec\n",
        "    # mean = 0, stddev = 1, since Z-transform was calculated\n",
        "    y = norm.pdf(x,0,1);\n",
        "    y2 = norm.pdf(x_all,0,1);\n",
        "\n",
        "    # build the plot\n",
        "    fig, ax = plt.subplots(figsize=(9,6));\n",
        "    #plt.style.use('fivethirtyeight');\n",
        "    ax.plot(x_all,y2);\n",
        "\n",
        "    ax.fill_between(x,y,0, alpha=0.3, color='b');\n",
        "    ax.fill_between(x_all,y2,0, alpha=0.1);\n",
        "    ax.set_xlim([-4,4]);\n",
        "    ax.set_xlabel('# of Standard Deviations Outside the Mean');\n",
        "    ax.set_yticklabels([]);\n",
        "    ax.set_title(f'{model_name} {error} Std Dev');\n",
        "\n",
        "    plt.savefig('normal_curve.png', dpi=72, bbox_inches='tight');\n",
        "    plt.grid(True);\n",
        "    plt.tight_layout();\n",
        "    #plt.show()\n",
        "    # save the current figure\n",
        "    pdf.savefig(fig);\n",
        "    ## destroy the current figure\n",
        "    plt.clf()\n",
        "\n",
        "    # close the object\n",
        "    pdf.close()\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "## Get a PDF of the MAE, RMSD and cov.\n",
        "def prob_dist(stats_list2, name, error_type, num):    \n",
        "    model_name = name\n",
        "    model_dir = model_directory()\n",
        "    path = get_path()\n",
        "    path = path + f\"{model_name}/\"\n",
        "\n",
        "\n",
        "    error = error_type\n",
        "    pdf = PdfPages(path + f\"prob_dist_pic_{error}.pdf\")\n",
        "    fig = plt.figure()\n",
        "\n",
        "    import seaborn as sns\n",
        "    sns.distplot(stats_list2.iloc[:-3,num], color=\"darkslategrey\");\n",
        "    plt.xlabel(\"Force [newtons]\", labelpad=14);\n",
        "    plt.ylabel(\"Probability of Occurence\", labelpad=14);\n",
        "    plt.title(f\"Probability Distribution of {error}\", fontsize=20);\n",
        "    plt.grid(True);\n",
        "    plt.tight_layout();\n",
        "\n",
        "    #plt.show()\n",
        "    # save the current figure\n",
        "    pdf.savefig(fig);\n",
        "    # destroy the current figure\n",
        "    plt.clf()\n",
        "    plt.close('all') ## added this due to runtime warning, more than 20 figs open\n",
        "    # close the object\n",
        "    pdf.close()\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n",
            "learning rate = 0.0005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrTtylzSDS7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_runner(name):   \n",
        "    stats_df = tests(name) # Run tests on testing data and save generated plots to Google Drive\n",
        "    stats(stats_df, name) # Record stats and save to Google Drive\n",
        "    for i in range(1,4): # 1 to 3 = the colunms in the stats_list DataFrame\n",
        "        if i ==1:\n",
        "            error_type = 'MAE' # mean absolur error\n",
        "        elif i == 2:\n",
        "            error_type = 'RMSE' # root mean squared error\n",
        "        elif i == 3:\n",
        "            error_type = 'cov' # coefficient of variance\n",
        "\n",
        "        prob_dist(stats_df, name, error_type, i) # Gen prob_dist and save to GD\n",
        "        \n",
        "        gauss_plot(stats_df, name, error_type, i) # Gen Gauss plots and save to GD\n",
        "    print(\"Done\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3huiPBCNEufa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Get num\n",
        "feature_num = get_features()\n",
        "url = 'https://raw.githubusercontent.com/PorkPy/LSTM-Force-Predictor/master/80k_data/cart_data_plus_rotation.csv'\n",
        "\n",
        "url2 = 'https://raw.githubusercontent.com/PorkPy/LSTM-Force-Predictor/master/80k_data/4_joints_3_force_1_forceVec.csv'\n",
        "\n",
        "url3 = 'https://raw.githubusercontent.com/PorkPy/LSTM-Force-Predictor/master/80k_data/mean_force_data.csv'\n",
        "\n",
        "\n",
        "data = pd.read_csv(url)\n",
        "data2 = pd.read_csv(url2)\n",
        "data3 = pd.read_csv(url3)\n",
        "main_seq = data"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4_srmpGE0q5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e773acaa-c441-4463-8626-4d1e10c9bbe4"
      },
      "source": [
        "features = data\n",
        "feature_scaler = StandardScaler()\n",
        "features = feature_scaler.fit_transform(features)\n",
        "\n",
        "targets = data2.iloc[:,:3]\n",
        "target_scaler = StandardScaler()\n",
        "targets = target_scaler.fit_transform(targets)\n",
        "\n",
        "force_vec = pd.DataFrame(data3.iloc[:,-1])\n",
        "\n",
        "features = pd.DataFrame(features)\n",
        "targets = pd.DataFrame(targets)\n",
        "data = pd.concat([targets, features, force_vec], axis=1)\n",
        "data.columns = [['Fx', 'Fy', 'Fz', 'x', 'y', 'z', 'Rx', 'Ry', 'Rz', 'force vec']]\n",
        "display(data)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Fx</th>\n",
              "      <th>Fy</th>\n",
              "      <th>Fz</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>Rx</th>\n",
              "      <th>Ry</th>\n",
              "      <th>Rz</th>\n",
              "      <th>force vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.229527</td>\n",
              "      <td>0.132190</td>\n",
              "      <td>0.064890</td>\n",
              "      <td>-1.136618</td>\n",
              "      <td>0.408166</td>\n",
              "      <td>-0.550866</td>\n",
              "      <td>0.521896</td>\n",
              "      <td>-0.377128</td>\n",
              "      <td>-0.302726</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.218995</td>\n",
              "      <td>0.116413</td>\n",
              "      <td>0.061217</td>\n",
              "      <td>-1.136679</td>\n",
              "      <td>0.408226</td>\n",
              "      <td>-0.551257</td>\n",
              "      <td>0.521890</td>\n",
              "      <td>-0.376738</td>\n",
              "      <td>-0.302744</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.229527</td>\n",
              "      <td>0.125879</td>\n",
              "      <td>0.063053</td>\n",
              "      <td>-1.136613</td>\n",
              "      <td>0.408126</td>\n",
              "      <td>-0.550886</td>\n",
              "      <td>0.521903</td>\n",
              "      <td>-0.375445</td>\n",
              "      <td>-0.302700</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.232159</td>\n",
              "      <td>0.124827</td>\n",
              "      <td>0.066726</td>\n",
              "      <td>-1.136642</td>\n",
              "      <td>0.408244</td>\n",
              "      <td>-0.551756</td>\n",
              "      <td>0.521884</td>\n",
              "      <td>-0.375788</td>\n",
              "      <td>-0.302735</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.224260</td>\n",
              "      <td>0.140606</td>\n",
              "      <td>0.063053</td>\n",
              "      <td>-1.136663</td>\n",
              "      <td>0.408174</td>\n",
              "      <td>-0.550305</td>\n",
              "      <td>0.521909</td>\n",
              "      <td>-0.376406</td>\n",
              "      <td>-0.302726</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71995</th>\n",
              "      <td>0.303249</td>\n",
              "      <td>0.285764</td>\n",
              "      <td>0.239361</td>\n",
              "      <td>1.972838</td>\n",
              "      <td>0.565879</td>\n",
              "      <td>2.281913</td>\n",
              "      <td>-1.911302</td>\n",
              "      <td>-1.151414</td>\n",
              "      <td>0.913013</td>\n",
              "      <td>5.038129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71996</th>\n",
              "      <td>0.342744</td>\n",
              "      <td>0.335202</td>\n",
              "      <td>0.239361</td>\n",
              "      <td>1.929224</td>\n",
              "      <td>0.529467</td>\n",
              "      <td>2.223429</td>\n",
              "      <td>-1.911355</td>\n",
              "      <td>-1.136161</td>\n",
              "      <td>0.905846</td>\n",
              "      <td>4.659258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71997</th>\n",
              "      <td>0.292717</td>\n",
              "      <td>0.319424</td>\n",
              "      <td>0.220995</td>\n",
              "      <td>1.886598</td>\n",
              "      <td>0.497976</td>\n",
              "      <td>2.169416</td>\n",
              "      <td>-1.911478</td>\n",
              "      <td>-1.115511</td>\n",
              "      <td>0.900044</td>\n",
              "      <td>4.305321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71998</th>\n",
              "      <td>0.463860</td>\n",
              "      <td>0.241586</td>\n",
              "      <td>0.362408</td>\n",
              "      <td>1.845012</td>\n",
              "      <td>0.474289</td>\n",
              "      <td>2.109868</td>\n",
              "      <td>-1.911668</td>\n",
              "      <td>-1.100489</td>\n",
              "      <td>0.895936</td>\n",
              "      <td>3.918005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71999</th>\n",
              "      <td>0.324313</td>\n",
              "      <td>0.292075</td>\n",
              "      <td>0.424851</td>\n",
              "      <td>1.802207</td>\n",
              "      <td>0.453373</td>\n",
              "      <td>2.064608</td>\n",
              "      <td>-1.911762</td>\n",
              "      <td>-1.086311</td>\n",
              "      <td>0.891849</td>\n",
              "      <td>3.574867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Fx        Fy        Fz  ...        Ry        Rz force vec\n",
              "0      0.229527  0.132190  0.064890  ... -0.377128 -0.302726  0.000000\n",
              "1      0.218995  0.116413  0.061217  ... -0.376738 -0.302744  0.000000\n",
              "2      0.229527  0.125879  0.063053  ... -0.375445 -0.302700  0.000000\n",
              "3      0.232159  0.124827  0.066726  ... -0.375788 -0.302735  0.000000\n",
              "4      0.224260  0.140606  0.063053  ... -0.376406 -0.302726  0.000000\n",
              "...         ...       ...       ...  ...       ...       ...       ...\n",
              "71995  0.303249  0.285764  0.239361  ... -1.151414  0.913013  5.038129\n",
              "71996  0.342744  0.335202  0.239361  ... -1.136161  0.905846  4.659258\n",
              "71997  0.292717  0.319424  0.220995  ... -1.115511  0.900044  4.305321\n",
              "71998  0.463860  0.241586  0.362408  ... -1.100489  0.895936  3.918005\n",
              "71999  0.324313  0.292075  0.424851  ... -1.086311  0.891849  3.574867\n",
              "\n",
              "[72000 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1oA9E7UE2aB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ba2ab148-9f61-4557-9fc1-3f5fedcd19cd"
      },
      "source": [
        "n=1000  ## num samples per trajectory/sequence.\n",
        "batchesx = [data[i:i + n] for i in range(0, len(data), n)] ## a list comprehension to build the data batches.\n",
        "print(len(batchesx))\n",
        "\n",
        "random.seed(get_random_seed())\n",
        "random.shuffle(batchesx)\n",
        "\n",
        "\n",
        "batches = batchesx[:60] ## Training batches up to the 60th sequence/trajectory.\n",
        "val_batches = batchesx[60:] ## Validation batches starting from the 60th sequence.\n",
        "\n",
        "## Append extra validation batches to even the number training and validation batches.\n",
        "## This is because the training loop performs a validation test on each iteration\n",
        "## and so always needs something to validate against.  \n",
        "while len(val_batches) < len(batches): \n",
        "    for i in batchesx[60:]:\n",
        "        val_batches.append(i)\n",
        "random.shuffle(val_batches)\n",
        "\n",
        "test_batches = batchesx[60:] ## Testing batches, same as validation batches, without the appendages.\n",
        "print(len(batches), len(val_batches), len(test_batches))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72\n",
            "60 60 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpfScpNPEPbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_batch(batch_number, start_seq):\n",
        "    \n",
        "    seq_size = get_seq_length() ## 1000 for testing 50-100 for training\n",
        "    features_num = get_features()\n",
        "\n",
        "    X_test = []\n",
        "\n",
        "    data = test_batches[batch_number].reset_index(drop=True)\n",
        "    data= data[start_seq:seq_size+start_seq]\n",
        "\n",
        "    if features_num == 4:\n",
        "        features = data[['joint_0', 'joint_2', 'joint_4', 'joint_5']]\n",
        "    else:\n",
        "        features = data[['x', 'y', 'z', 'Rx', 'Ry', 'Rz']]\n",
        "    features = np.asarray(features)\n",
        "    y_test = data.iloc[:,-1]\n",
        "    \n",
        "    for i in range(len(features)):           \n",
        "   \n",
        "        X =(features[:i+1])\n",
        "        an_array = np.array(X)\n",
        "        shape = np.shape(X)\n",
        "        temp = np.zeros((seq_size, features_num))\n",
        "        temp[(seq_size-shape[0]):,:shape[1]] = an_array\n",
        "        X_test.append(temp)\n",
        "\n",
        "    \n",
        "    X_test = torch.cuda.FloatTensor(X_test)\n",
        "    return(X_test, y_test)\n",
        "  "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv_92GfcDeYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1f093b45-3df9-4bf9-c7e6-ab634a3c383f"
      },
      "source": [
        "name = f'model1001_v92'\n",
        "test_runner(name)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the directory /content/drive/My Drive/PhD/PhD/lstm/model1001/model1001_v92/ \n",
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}