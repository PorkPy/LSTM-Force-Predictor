{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_predictor_batches.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQVk9bq+NsnqlyBS0uwgwA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PorkPy/LSTM-Force-Predictor/blob/master/test_predictor_batches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTFsIZa-keYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d47dc6dc-aa78-44d9-e0c4-acdc855a0de6"
      },
      "source": [
        "% reset -f\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import sys\n",
        "print('__Python VERSION:', sys.version)\n",
        "print('__pyTorch VERSION:', torch.__version__)\n",
        "print('__CUDA VERSION')\n",
        "from subprocess import call\n",
        "# call([\"nvcc\", \"--version\"]) does not work\n",
        "! nvcc --version\n",
        "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
        "print('__Devices')\n",
        "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
        "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
        "\n",
        "print ('Available devices ', torch.cuda.device_count())\n",
        "print ('Current cuda device ', torch.cuda.current_device())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__Python VERSION: 3.6.9 (default, Apr 18 2020, 01:56:04) \n",
            "[GCC 8.4.0]\n",
            "__pyTorch VERSION: 1.5.1+cu101\n",
            "__CUDA VERSION\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "__CUDNN VERSION: 7603\n",
            "__Number CUDA Devices: 1\n",
            "__Devices\n",
            "Active CUDA Device: GPU 0\n",
            "Available devices  1\n",
            "Current cuda device  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG73I9TD9kyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "079214dc-0bb7-4b5e-ebab-a4f96c137a6f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H53xwWz29qIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d531d285-74e4-4ef8-e67d-05d8323d6b9c"
      },
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch import nn, optim\n",
        "import random\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "from scipy.stats import norm\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import warnings\n",
        "#warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "## Set random seed for numpy and Torch\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6b78f58ab0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1arESxXR-GgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99ff6b7b-c0bf-4e93-dc90-c23fbdf4c323"
      },
      "source": [
        "### MODEL PARAMETERS ###\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_num  = '75'        ## model number to save new models with\n",
        "params     = '75_v300' ## which model params to load...\n",
        "warm_start = True       ## ...and if to load them.\n",
        "model_dir  = 'model75'   ## Directory for specific model being trained. \n",
        "seq_length = 100         ## The length of the trajectory sequence batch.\n",
        "epochs     = 1         ## Number of full passes through the whole dataset.\n",
        "hidden     = 60          ## Number of nodes in the LSTM layers.\n",
        "lr         = 0.0004      ## Learning rate.\n",
        "features   = 4           ## 4 features for joint data, 6 features for cartesian data.\n",
        "fc         = 1           ## Number of fully connected layers. 1 or 2.\n",
        "path       = f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/\" ## Save directory.\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def model_number():\n",
        "    return model_num\n",
        "\n",
        "def load_params():\n",
        "    return params\n",
        "\n",
        "def model_directory():\n",
        "    return model_dir\n",
        "\n",
        "def get_seq_length():\n",
        "    return seq_length\n",
        "\n",
        "def get_epochs():\n",
        "    return epochs\n",
        "\n",
        "def get_warm_start():\n",
        "    return warm_start\n",
        "\n",
        "def get_hidden():\n",
        "    return hidden\n",
        "\n",
        "def get_lr():\n",
        "    return lr\n",
        "\n",
        "def get_path():\n",
        "    return path\n",
        "\n",
        "def get_features():\n",
        "    return features\n",
        "\n",
        "def get_fc():\n",
        "    return fc\n",
        "\n",
        "## Dictionary with which to save paramers.\n",
        "param = {'Model Num':model_num, \n",
        "          'Seq Length': seq_length,\n",
        "          'Epochs': epochs,\n",
        "          'Warm Start': warm_start,\n",
        "          'Hidden Size': hidden,\n",
        "          'Learning Rate': lr,\n",
        "          'Data': features, \n",
        "          'Num LSTM Layers':2,\n",
        "          'Num FC Layers':1}\n",
        "\n",
        "## Create new directory in perent directory to save parameters.\n",
        "try:\n",
        "    os.makedirs(path)\n",
        "except OSError:\n",
        "    print (\"Creation of the directory %s failed\" % path)\n",
        "else:\n",
        "    print (\"Successfully created the directory %s \" % path)\n",
        "\n",
        "\n",
        "## create a pandas data frame of the model parameters and save to csv.\n",
        "param = pd.DataFrame(param, index=[0])\n",
        "param.to_csv(path + \"lstm_params.csv\", index=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creation of the directory /content/drive/My Drive/PhD/PhD/lstm/model75/ failed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3FNAuGK9b6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tests(model_name):\n",
        "    \n",
        "    seq_len = get_seq_length()\n",
        "    model_name = model_name\n",
        "    model_dir = model_directory()\n",
        "    features_num = get_features()\n",
        "\n",
        "    ## Create new directory in perent directory\n",
        "    path = f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/{model_name}/\"\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % path)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % path)\n",
        "\n",
        "    stats_list = []\n",
        "    pdf = PdfPages(f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/{model_name}/testing_traj_pics_{model_name}.pdf\")\n",
        "    fig = plt.figure()\n",
        "\n",
        "\n",
        "    for traj in range(len(test_batches)):\n",
        "        whole_pred = []\n",
        "        whole_y_test = []\n",
        "\n",
        "        for start_seq in range(10): \n",
        "            start_seqx = start_seq*seq_length ## get the next sequence start position\n",
        "\n",
        "            Xtest, ytest, jim, scaler = get_test_batch(traj, start_seqx)\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                model.reset_hidden_state()\n",
        "\n",
        "                x = iter(Xtest)\n",
        "                test_seq = Xtest[0].reshape(-1,seq_len,features_num)#.reshape(1,200,4) # input first sequence from trajectory/batch\n",
        "                preds = [] # create a list to store predictions.\n",
        "                for i in range(len(Xtest)): # for each sequence i in the trajectory,\n",
        "                    y_test_pred = model(test_seq).to(device) # send sequence to model,\n",
        "                    pred = torch.flatten(y_test_pred).item() # reshape the model output,\n",
        "                    preds.append(pred) # and append to the list of predictions - preds.\n",
        "                    new_seq = next(x).reshape(-1,seq_len,features_num)#.reshape(1,200,4) # Change sequence to the next one in the list.\n",
        "                    test_seq = torch.cuda.FloatTensor(new_seq).view(1, seq_len, -1) # change sequence to a torch Tensor\n",
        "                    #model.reset_hidden_state()\n",
        "\n",
        "\n",
        "            whole_pred.append(preds)\n",
        "        preds2 = np.asarray(whole_pred)\n",
        "        preds = scaler.inverse_transform(preds2).reshape(-1,1)\n",
        "            \n",
        "\n",
        "        # Mean Absolute Error\n",
        "        MAE_list = []\n",
        "        for i,j in zip(preds, ytest):\n",
        "            error = np.abs(i-j)\n",
        "            MAE_list.append(error)\n",
        "        MAE = float(\"{:.3f}\".format(np.mean(MAE_list)))\n",
        "        #print(\"MAE\",\"{:.3f}\".format(MAE),'N')\n",
        "\n",
        "        # Coefficient of Variance\n",
        "        mean = np.mean(data.iloc[:,-1]) # mean of all dependent variables.\n",
        "        cov_list = []\n",
        "        for i,j in zip(preds, ytest):\n",
        "            sq_dev = (i-j)**2\n",
        "            cov_list.append(sq_dev)    \n",
        "        MSD = np.mean(cov_list) # mean square deviation\n",
        "        RMSD = np.sqrt(MSD) # root mean square deviation\n",
        "        cov = RMSD/mean # coefficient of variance\n",
        "        RMSD = float(\"{:.3f}\".format(RMSD))\n",
        "        cov =  float(\"{:.3f}\".format(cov))\n",
        "        #print(\"COV:\",\"{:.3f}\".format(cov))\n",
        "        \n",
        "    \n",
        "        my_dict = {'Trajectory':traj,\n",
        "                'MAE': MAE, \n",
        "                'RMSD':RMSD,\n",
        "                'cov': cov, # Used to normalise the RMSD accross all the data\n",
        "        }\n",
        "        stats_list.append(my_dict)\n",
        "\n",
        "\n",
        "        # Plot forces\n",
        "        predicted_cases = preds\n",
        "        true_cases = ytest\n",
        "        # Add title and axis names\n",
        "        plt.title(f'Force Trajectory {traj}')\n",
        "        plt.xlabel('Sample num')\n",
        "        plt.ylabel('Force (N)')\n",
        "        #plt.plot(jim,label='Sequence')\n",
        "        plt.plot(true_cases[:,-1], label='Real Force')\n",
        "        plt.plot(predicted_cases[:,-1], label='Predicted Force')\n",
        "        plt.legend();\n",
        "        # save the current figure\n",
        "        pdf.savefig(fig);\n",
        "        # destroy the current figure\n",
        "        plt.clf()\n",
        "\n",
        "    # close the object\n",
        "    # fig = plt.figure()\n",
        "    # plt.plot(train_hist, label=\"Training loss\")\n",
        "    # plt.plot(test_hist, label=\"Test loss\")\n",
        "    # plt.legend();\n",
        "    # pdf.savefig(fig)\n",
        "    # plt.clf\n",
        "    pdf.close()\n",
        "    stats_list = pd.DataFrame(stats_list)\n",
        "    return stats_list\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "def stats(stats_list2, model_name):\n",
        "    \n",
        "    #display(stats_list2)\n",
        "    #display(stats_list2['MAE'])\n",
        "\n",
        "    mean_list = {\n",
        "                'MAE' :float(\"{:.3f}\".format(np.mean(stats_list2['MAE']))),\n",
        "                'RMSD':float(\"{:.3f}\".format(np.mean(stats_list2['RMSD']))),\n",
        "                'cov' :float(\"{:.3f}\".format(np.mean(stats_list2['cov'])))\n",
        "    }\n",
        "\n",
        "    std_dev = {\n",
        "                'MAE' :float(\"{:.3f}\".format(np.std(stats_list2['MAE']))),\n",
        "                'RMSD':float(\"{:.3f}\".format(np.std(stats_list2['RMSD']))),\n",
        "                'cov' :float(\"{:.3f}\".format(np.std(stats_list2['cov'])))\n",
        "    }\n",
        "\n",
        "    max_list = {\n",
        "                'MAE' :float(stats_list2['MAE'].max()),\n",
        "                'RMSD':float(stats_list2['RMSD'].max()),\n",
        "                'cov' :float(stats_list2['cov'].max())\n",
        "    }\n",
        "\n",
        "    stats_list2 = stats_list2.append(mean_list, ignore_index=True).fillna('Grand Mean')\n",
        "    stats_list2 = stats_list2.append(std_dev, ignore_index=True).fillna('Standard Dev')\n",
        "    stats_list2 = stats_list2.append(max_list, ignore_index=True).fillna('Max Value')\n",
        "\n",
        "    #display(stats_list2)\n",
        "    model_name = model_name\n",
        "    model_dir = model_directory()\n",
        "\n",
        "    stats_list2.to_csv(f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/{model_name}/lstm_model_testing_metrics_{model_name}.csv\", index=False)\n",
        "    return stats_list2\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "def gauss_plot(stats_list2, name, error_type, num):\n",
        "    import matplotlib.pyplot as plt\n",
        "    model_name = name\n",
        "    model_dir = model_directory()\n",
        "\n",
        "    error = error_type\n",
        "    pdf = PdfPages(f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/{model_name}/testing_gauss_pic_{error}.pdf\")\n",
        "    fig = plt.figure()\n",
        "    \n",
        "    # define constants\n",
        "    mu = np.mean(stats_list2.iloc[:-3,num]) \n",
        "    sigma = np.sqrt(np.var(stats_list2.iloc[:-3,num]))\n",
        "    x1 = np.min(stats_list2.iloc[:-3,num])\n",
        "    x2 = np.max(stats_list2.iloc[:-3,num])\n",
        "    # print(mu)\n",
        "    # print(sigma)\n",
        "    # print(x1)\n",
        "    # print(x2)\n",
        "\n",
        "    # calculate the z-transform\n",
        "    z1 = ( x1 - mu ) / sigma\n",
        "    z2 = ( x2 - mu ) / sigma\n",
        "\n",
        "    x = np.arange(z1, z2, 0.001) # range of x in spec\n",
        "    x_all = np.arange(-10, 10, 0.001) # entire range of x, both in and out of spec\n",
        "    # mean = 0, stddev = 1, since Z-transform was calculated\n",
        "    y = norm.pdf(x,0,1)\n",
        "    y2 = norm.pdf(x_all,0,1)\n",
        "\n",
        "    # build the plot\n",
        "    fig, ax = plt.subplots(figsize=(9,6))\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    ax.plot(x_all,y2)\n",
        "\n",
        "    ax.fill_between(x,y,0, alpha=0.3, color='b')\n",
        "    ax.fill_between(x_all,y2,0, alpha=0.1)\n",
        "    ax.set_xlim([-4,4])\n",
        "    ax.set_xlabel('# of Standard Deviations Outside the Mean')\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_title(f'{model_name} {error} Std Dev')\n",
        "\n",
        "    plt.savefig('normal_curve.png', dpi=72, bbox_inches='tight');\n",
        "    plt.grid(True);\n",
        "    #plt.show()\n",
        "\n",
        "    # save the current figure\n",
        "    pdf.savefig(fig);\n",
        "    # destroy the current figure\n",
        "    plt.clf()\n",
        "\n",
        "    # close the object\n",
        "    pdf.close()\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "def prob_dist(stats_list2, name, error_type, num):    \n",
        "    model_name = name\n",
        "    model_dir = model_directory()\n",
        "\n",
        "    error = error_type\n",
        "    pdf = PdfPages(f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/{model_name}/testing_prob_dist_pic_{error}.pdf\")\n",
        "    fig = plt.figure()\n",
        "\n",
        "    import seaborn as sns\n",
        "    sns.distplot(stats_list2.iloc[:-3,num], color=\"darkslategrey\");\n",
        "    plt.xlabel(\"Force [newtons]\", labelpad=14);\n",
        "    plt.ylabel(\"Probability of Occurence\", labelpad=14);\n",
        "    plt.title(f\"Probability Distribution of {error}\", fontsize=20);\n",
        "    #plt.show()\n",
        "    # save the current figure\n",
        "    pdf.savefig(fig);\n",
        "    # destroy the current figure\n",
        "    plt.clf()\n",
        "\n",
        "    # close the object\n",
        "    pdf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccsDEuXw-IJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_runner(name):   \n",
        "    stats_df = tests(name) # Run tests on testing data and save generated plots to Google Drive\n",
        "    stats(stats_df, name) # Record stats and save to Google Drive\n",
        "    for i in range(1,4): # 1 to 3 = the colunms in the stats_list DataFrame\n",
        "        if i ==1:\n",
        "            error_type = 'MAE' # mean absolur error\n",
        "        elif i == 2:\n",
        "            error_type = 'RMSE' # root mean squared error\n",
        "        elif i == 3:\n",
        "            error_type = 'cov' # coefficient of variance\n",
        "\n",
        "        prob_dist(stats_df, name, error_type, i) # Gen prob_dist and save to GD\n",
        "        \n",
        "        gauss_plot(stats_df, name, error_type, i) # Gen Gauss plots and save to GD\n",
        "    print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGhePT9C-McY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ForcePredictor(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features, n_hidden, seq_len, n_layers=2, ignore_zero=True):\n",
        "        super(ForcePredictor, self).__init__()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device(\"cuda:0\")\n",
        "            print(\"Running on the GPU\")\n",
        "        else:\n",
        "            device = torch.device(\"cpu\")\n",
        "            print(\"Running on CPU\")\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        self.seq_len = seq_len\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "          input_size=n_features,\n",
        "          hidden_size=n_hidden,\n",
        "          num_layers=n_layers,\n",
        "          dropout=0.5)\n",
        "        \n",
        "        fc = get_fc() ## get num of FC layers\n",
        "\n",
        "        if fc == 1:\n",
        "            self.linear1 = nn.Linear(in_features=n_hidden, out_features=1)\n",
        "            \n",
        "        elif fc == 2:\n",
        "            self.linear1 = nn.Linear(in_features=n_hidden, out_features=60)\n",
        "            self.linear2 = nn.Linear(in_features=60, out_features=1)\n",
        "\n",
        "        elif fc == 3:\n",
        "            self.linear1 = nn.Linear(in_features=60, out_features=60)\n",
        "            self.linear2 = nn.Linear(in_features=n_hidden, out_features=60)\n",
        "            self.linear3 = nn.Linear(in_features=60, out_features=1)\n",
        "        \n",
        "    def reset_hidden_state(self):\n",
        "        self.hidden = (\n",
        "            torch.zeros(self.n_layers, self.seq_len, self.n_hidden).to(device),\n",
        "            torch.zeros(self.n_layers, self.seq_len, self.n_hidden).to(device)\n",
        "        )\n",
        "\n",
        "    def forward(self, sequences):\n",
        "        \n",
        "        fc = get_fc() ## get num of FC layers\n",
        "\n",
        "        lstm_out, self.hidden = self.lstm(sequences.view(len(sequences), self.seq_len, -1),self.hidden)\n",
        "        last_time_step = lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n",
        "\n",
        "        if fc == 1:\n",
        "            y_pred = self.linear1(last_time_step)\n",
        "\n",
        "        if fc == 2:\n",
        "            y_pred = F.leaky_relu(self.linear1(last_time_step))\n",
        "            y_pred = self.linear3(y_pred)\n",
        "\n",
        "        if fc == 3:\n",
        "            y_pred = F.leaky_relu(self.linear1(last_time_step))\n",
        "            y_pred = F.leaky_relu(self.linear2(y_pred))\n",
        "            y_pred = self.linear3(y_pred)\n",
        "\n",
        "       \n",
        "\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3mcFAjZ-TaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fe59146-1183-479f-df8a-3ca72bd07933"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on CPU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UzJVziL-XDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model):\n",
        "   \n",
        "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)#0.0007  \n",
        "    num_epochs = get_epochs() #1600 #600\n",
        "    train_hist = np.zeros(num_epochs)\n",
        "    test_hist = np.zeros(num_epochs)\n",
        "              \n",
        "    params = load_params() # model num and version num: 4_v100.\n",
        "    PATH = f\"/content/drive/My Drive/PhD/PhD/lstm/model_params{params}.pt\"     \n",
        "    checkpoint = torch.load(PATH)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    for state in optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.cuda()\n",
        "    #num_epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    \n",
        "\n",
        "    for t in range( num_epochs):\n",
        "        for j in range(len(batches)):\n",
        "            \n",
        "            train_data, train_labels, test_data, test_labels = get_batches(j)\n",
        "            #if t % 100 == 0:#100 is good so far\n",
        "            model.reset_hidden_state() # Requiered because he hiddent state was forgetting too early. \n",
        "            y_pred = model(train_data)\n",
        "            loss = loss_fn(y_pred.float(), train_labels)\n",
        "\n",
        "            if test_data is not None:\n",
        "                with torch.no_grad():\n",
        "                    y_test_pred = model(test_data)\n",
        "                    test_loss = loss_fn(y_test_pred.float(), test_labels)\n",
        "                test_hist[t] = test_loss.item()\n",
        "\n",
        "                if t % 10 == 0:  \n",
        "                    print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n",
        "            elif t % 10 == 0:\n",
        "                  print(f'Epoch {t} train loss: {loss.item()}')\n",
        "\n",
        "            train_hist[t] = loss.item()\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            model = model.to(device)\n",
        "            optimizer.step()\n",
        "            #print(model.linear4.weight.data) # Check weights are being updated.\n",
        "\n",
        "            \n",
        "\n",
        "    return model.eval(), train_hist, test_hist, optimizer, t, loss_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgB--CEp-bc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = get_features()\n",
        "if features == 4:\n",
        "    url = 'https://raw.githubusercontent.com/PorkPy/LSTM-Force-Predictor/master/80k_data/mean_force_data.csv'\n",
        "else:\n",
        "    url = 'https://raw.githubusercontent.com/PorkPy/LSTM-Force-Predictor/master/80k_data/cart_force.csv'\n",
        "\n",
        "data = pd.read_csv(url)\n",
        "main_seq = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMGvgZ7A-fyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "395b40a1-eaf0-4a38-ee65-23d32667354e"
      },
      "source": [
        "n=1000 # changed to 990 due to removing the first 10 samples used to average the rest of the traj\n",
        "batchesx = [data[i:i + n] for i in range(0, len(data), n)]\n",
        "print(len(batchesx))\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(batchesx)\n",
        "\n",
        "\n",
        "## clean_data len = 64\n",
        "batches = batchesx[:1]#clean_data #high_force_list[:20]\n",
        "val_batches = batchesx[:60]#clean_data #high_force_list[:20] \n",
        "test_batches = batchesx[60:]#test_data #high_force_list#[7:14]\n",
        "print(len(batches), len(val_batches), len(test_batches))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72\n",
            "1 60 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KLDRD_6-jDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_batch(batch_number, start_seq):\n",
        "    \n",
        "    seq_size = get_seq_length()\n",
        "    features_num = get_features()\n",
        "\n",
        "    X_test = []\n",
        "\n",
        "    data = test_batches[batch_number].reset_index(drop=True)\n",
        "    target_data = data\n",
        "    data= data[start_seq:seq_size+start_seq]\n",
        "\n",
        "    if features_num == 4:\n",
        "        features = data[['joint_0', 'joint_2', 'joint_4', 'joint_5']]\n",
        "    else:\n",
        "        features = data[['x', 'y', 'z', 'Rx', 'Ry', 'Rz']]\n",
        "    features = np.asarray(features)\n",
        "\n",
        "    scaler2 = StandardScaler()\n",
        "    joint_scaler = np.asarray(features)\n",
        "    joint_scaler = joint_scaler.reshape(-1, features_num)\n",
        "    scaler2 = scaler2.fit(joint_scaler) \n",
        "    features = scaler2.transform(features)\n",
        "\n",
        "    targets = target_data.iloc[:,-1]\n",
        "    targets = np.asarray(targets)\n",
        "    targets = targets.reshape(-1,1)\n",
        "    \n",
        "    for i in range(len(features)):           \n",
        "   \n",
        "        X =(features[:i+1])\n",
        "        an_array = np.array(X)\n",
        "        shape = np.shape(X)\n",
        "        temp = np.zeros((seq_size, features_num))\n",
        "        temp[(seq_size-shape[0]):,:shape[1]] = an_array\n",
        "        X_test.append(temp)\n",
        "        y_test = targets\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    force_scaler = np.asarray(y_test)\n",
        "    force_scaler = force_scaler.reshape(-1,1)\n",
        "    scaler = scaler.fit(force_scaler)    \n",
        "    #y_test = scaler.transform(y_test)\n",
        "   \n",
        "    \n",
        "    X_test = torch.cuda.FloatTensor(X_test)\n",
        "    #y_test = torch.cuda.FloatTensor(y_test)\n",
        "    #print(data, '\\n')\n",
        "    #print( X_test.shape, y_test.shape)\n",
        "    jim = targets\n",
        "    return(X_test, y_test, jim, scaler)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKPIXZ2_-nEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(batch_num):  \n",
        "\n",
        "    features_num = get_features()\n",
        "    \n",
        "    seq_size = get_seq_length() # 1000 = full trajectories\n",
        "\n",
        "    # random.seed(batch_num)\n",
        "    # random.shuffle(batches) # ive turned this off to test new cleaned data\n",
        "\n",
        "    # Randomise the fetching of new data to break the corrolation of training.\n",
        "    #print(batch_num)\n",
        "    #print(type(batches[batch_num])) \n",
        "    data = batches[batch_num].reset_index(drop=True)\n",
        "    data= data[:seq_size]\n",
        "    ################################################\n",
        "\n",
        "    X_train = []\n",
        "    X_test = []\n",
        "    \n",
        "    if features_num == 4:\n",
        "        features = data[['joint_0', 'joint_2', 'joint_4', 'joint_5']]\n",
        "    else:\n",
        "        features = data[['x', 'y', 'z', 'Rx', 'Ry', 'Rz']]\n",
        "    features = np.asarray(features)\n",
        "\n",
        "    scaler2 = StandardScaler()\n",
        "    joint_scaler = np.asarray(features)\n",
        "    joint_scaler = joint_scaler.reshape(-1, features_num)\n",
        "    scaler2 = scaler2.fit(joint_scaler) \n",
        "    features = scaler2.transform(features)\n",
        "\n",
        "    targets = data.iloc[:,-1]\n",
        "    targets = np.asarray(targets)\n",
        "    targets = targets.reshape(-1,1)\n",
        "\n",
        "    for i in range(len(features)):           \n",
        "        \n",
        "        np.random.seed(42)\n",
        "       \n",
        "        X =(features[:i+1])\n",
        "        an_array = np.array(X)\n",
        "        shape = np.shape(X)\n",
        "        temp = np.zeros((seq_size, features_num))\n",
        "        temp[(seq_size-shape[0]):,:shape[1]] = an_array\n",
        "        X_train.append(temp)\n",
        "        y_train = targets\n",
        "    \n",
        "    ###############################\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    force_scaler = np.asarray(y_train)\n",
        "    force_scaler = force_scaler.reshape(-1,1)\n",
        "    scaler = scaler.fit(force_scaler)    \n",
        "    y_train = scaler.transform(y_train)\n",
        "    \n",
        "    ################################\n",
        "    data = val_batches[batch_num].reset_index(drop=True)\n",
        "    data= data[:seq_size]\n",
        "\n",
        "    if features_num == 4:\n",
        "        features = data[['joint_0', 'joint_2', 'joint_4', 'joint_5']]\n",
        "    else:\n",
        "        features = data[['x', 'y', 'z', 'Rx', 'Ry', 'Rz']]\n",
        "    features = np.asarray(features)\n",
        "\n",
        "    scaler2 = StandardScaler()\n",
        "    joint_scaler = np.asarray(features)\n",
        "    joint_scaler = joint_scaler.reshape(-1, features_num)\n",
        "    scaler2 = scaler2.fit(joint_scaler) \n",
        "    features = scaler2.transform(features)\n",
        "\n",
        "    targets = data.iloc[:,-1]\n",
        "    targets = np.asarray(targets)\n",
        "    targets = targets.reshape(-1,1)\n",
        "    \n",
        "    for i in range(len(features)):           \n",
        "   \n",
        "        X =(features[:i+1])\n",
        "        an_array = np.array(X)\n",
        "        shape = np.shape(X)\n",
        "        temp = np.zeros((seq_size, features_num))\n",
        "        temp[(seq_size-shape[0]):,:shape[1]] = an_array\n",
        "        X_test.append(temp)\n",
        "        y_test = targets\n",
        "\n",
        " #############################################\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    force_scaler = np.asarray(y_test)\n",
        "    force_scaler = force_scaler.reshape(-1,1)\n",
        "    scaler = scaler.fit(force_scaler)    \n",
        "    y_test = scaler.transform(y_test)\n",
        "\n",
        "###############################################\n",
        "\n",
        "    X_train = torch.cuda.FloatTensor(X_train) # Change data to tensors\n",
        "    y_train = torch.cuda.FloatTensor(y_train)\n",
        "    X_test = torch.cuda.FloatTensor(X_test)\n",
        "    y_test = torch.cuda.FloatTensor(y_test)\n",
        "    \n",
        "    #del targets, features, data, temp, an_array\n",
        "    \n",
        "    #print(data)\n",
        "    #print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "    return(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0ugc8Bl-r1m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9e69e250-8f15-4832-cf97-bdf2df565951"
      },
      "source": [
        "%%time\n",
        "\n",
        "seq_length = get_seq_length() # when using zero padding, this seq_length is a bit redundent but still has to match the zero's size.\n",
        "\n",
        "model = ForcePredictor(\n",
        "      n_features=get_features(), \n",
        "      n_hidden= 60, #32, #64\n",
        "      seq_len=seq_length, \n",
        "      n_layers=2\n",
        "    )\n",
        "\n",
        "model, train_hist, test_hist, optimizer, epochs, loss = train_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n",
            "Epoch 0 train loss: 0.19016505777835846 test loss: 0.19110210239887238\n",
            "CPU times: user 53.1 ms, sys: 1.98 ms, total: 55.1 ms\n",
            "Wall time: 57.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfLXf4GE-vfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "73196362-ab1a-4475-8224-7df84fe3a36b"
      },
      "source": [
        "model_num = model_number()\n",
        "name = f'model{model_num}_testing_metrics'\n",
        "test_runner(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creation of the directory /content/drive/My Drive/PhD/PhD/lstm/model75/model75_testing_metrics/ failed\n",
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}