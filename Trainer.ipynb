{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Trainer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PorkPy/LSTM-Force-Predictor/blob/master/Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtEIpTbrfxxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mzCKBtLA-zOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch import nn, optim\n",
        "import random\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "from scipy.stats import norm\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import warnings\n",
        "#warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "## Set random seed for numpy and Torch\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xNzK2S2_mdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5WXvVoh-zOu",
        "colab_type": "text"
      },
      "source": [
        "Check CUDA is available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJf9cG7o-zOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ryldrf8Qhv0",
        "colab_type": "text"
      },
      "source": [
        "User defined params\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35dozZZC3Nut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_number():\n",
        "    model_num = '22' # model number to save new models with\n",
        "    return model_num\n",
        "def load_params():\n",
        "    params = '20_v400' # which model params to load.\n",
        "    return params\n",
        "\n",
        "def model_directory():\n",
        "    model_dir = 'model22' # directory for specific model being trained. \n",
        "    return model_dir\n",
        "\n",
        "def get_seq_length():\n",
        "    seq_length = 1000\n",
        "    return seq_length\n",
        "\n",
        "def get_epochs():\n",
        "    epochs = 1100\n",
        "    return epochs\n",
        "\n",
        "#name = 'model7_v0' # filename to save test results to.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "O7ZKYszy-zQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def tests(model_name):\n",
        "    \n",
        "    seq_len = get_seq_length()\n",
        "    model_name = model_name\n",
        "    model_dir = model_directory()\n",
        "\n",
        "    ## Create new directory in perent directory\n",
        "    path = f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/{model_name}/\"\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % path)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % path)\n",
        "\n",
        "    stats_list = []\n",
        "    pdf = PdfPages(f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/{model_name}/testing_traj_pics_{model_name}.pdf\")\n",
        "    fig = plt.figure()\n",
        "\n",
        "    for traj in range(len(test_batches)):\n",
        "        Xtest, ytest, jim, scaler = get_test_batch(traj)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            model.reset_hidden_state()\n",
        "            \n",
        "            test_seq = Xtest[0].reshape(-1,seq_len,4)#.reshape(1,200,4) # input first sequence from trajectory/batch\n",
        "            preds = [] # create a list to store predictions.\n",
        "            for i in range(len(Xtest)-1): # for each sequence i in the trajectory,\n",
        "                y_test_pred = model(test_seq).to(device) # send sequence to model,\n",
        "                pred = torch.flatten(y_test_pred).item() # reshape the model output,\n",
        "                preds.append(pred) # and append to the list of predictions - preds.\n",
        "                new_seq = Xtest[i+1].reshape(-1,seq_len,4)#.reshape(1,200,4) # Change sequence to the next one in the list.\n",
        "                test_seq = torch.cuda.FloatTensor(new_seq).view(1, seq_len, -1) # change sequence to a torch Tensor\n",
        "                #model.reset_hidden_state()\n",
        "\n",
        "\n",
        "        preds2 = np.asarray(preds)\n",
        "        preds = scaler.inverse_transform(preds2).reshape(-1,1)\n",
        "\n",
        "        # Mean Absolute Error\n",
        "        MAE_list = []\n",
        "        for i,j in zip(preds, ytest):\n",
        "            error = np.abs(i-j)\n",
        "            MAE_list.append(error)\n",
        "        MAE = float(\"{:.3f}\".format(np.mean(MAE_list)))\n",
        "        #print(\"MAE\",\"{:.3f}\".format(MAE),'N')\n",
        "\n",
        "        # Coefficient of Variance\n",
        "        mean = np.mean(data.iloc[:,-1]) # mean of all dependent variables.\n",
        "        cov_list = []\n",
        "        for i,j in zip(preds, ytest):\n",
        "            sq_dev = (i-j)**2\n",
        "            cov_list.append(sq_dev)    \n",
        "        MSD = np.mean(cov_list) # mean square deviation\n",
        "        RMSD = np.sqrt(MSD) # root mean square deviation\n",
        "        cov = RMSD/mean # coefficient of variance\n",
        "        RMSD = float(\"{:.3f}\".format(RMSD))\n",
        "        cov =  float(\"{:.3f}\".format(cov))\n",
        "        #print(\"COV:\",\"{:.3f}\".format(cov))\n",
        "        \n",
        "    \n",
        "        my_dict = {'Trajectory':traj,\n",
        "                'MAE': MAE, \n",
        "                'RMSD':RMSD,\n",
        "                'cov': cov, # Used to normalise the RMSD accross all the data\n",
        "        }\n",
        "        stats_list.append(my_dict)\n",
        "\n",
        "\n",
        "        # Plot forces\n",
        "        predicted_cases = preds\n",
        "        true_cases = ytest\n",
        "        # Add title and axis names\n",
        "        plt.title(f'Force Trajectory {traj}')\n",
        "        plt.xlabel('Sample num')\n",
        "        plt.ylabel('Force (N)')\n",
        "        #plt.plot(jim,label='Sequence')\n",
        "        plt.plot(true_cases[:,-1], label='Real Force')\n",
        "        plt.plot(predicted_cases[:,-1], label='Predicted Force')\n",
        "        plt.legend();\n",
        "        # save the current figure\n",
        "        pdf.savefig(fig);\n",
        "        # destroy the current figure\n",
        "        plt.clf()\n",
        "\n",
        "    # close the object\n",
        "    # fig = plt.figure()\n",
        "    # plt.plot(train_hist, label=\"Training loss\")\n",
        "    # plt.plot(test_hist, label=\"Test loss\")\n",
        "    # plt.legend();\n",
        "    # pdf.savefig(fig)\n",
        "    # plt.clf\n",
        "    pdf.close()\n",
        "    stats_list = pd.DataFrame(stats_list)\n",
        "    return stats_list\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "def stats(stats_list2, model_name):\n",
        "    \n",
        "    #display(stats_list2)\n",
        "    #display(stats_list2['MAE'])\n",
        "\n",
        "    mean_list = {\n",
        "                'MAE' :float(\"{:.3f}\".format(np.mean(stats_list2['MAE']))),\n",
        "                'RMSD':float(\"{:.3f}\".format(np.mean(stats_list2['RMSD']))),\n",
        "                'cov' :float(\"{:.3f}\".format(np.mean(stats_list2['cov'])))\n",
        "    }\n",
        "\n",
        "    std_dev = {\n",
        "                'MAE' :float(\"{:.3f}\".format(np.std(stats_list2['MAE']))),\n",
        "                'RMSD':float(\"{:.3f}\".format(np.std(stats_list2['RMSD']))),\n",
        "                'cov' :float(\"{:.3f}\".format(np.std(stats_list2['cov'])))\n",
        "    }\n",
        "\n",
        "    max_list = {\n",
        "                'MAE' :float(stats_list2['MAE'].max()),\n",
        "                'RMSD':float(stats_list2['RMSD'].max()),\n",
        "                'cov' :float(stats_list2['cov'].max())\n",
        "    }\n",
        "\n",
        "    stats_list2 = stats_list2.append(mean_list, ignore_index=True).fillna('Grand Mean')\n",
        "    stats_list2 = stats_list2.append(std_dev, ignore_index=True).fillna('Standard Dev')\n",
        "    stats_list2 = stats_list2.append(max_list, ignore_index=True).fillna('Max Value')\n",
        "\n",
        "    #display(stats_list2)\n",
        "    model_name = model_name\n",
        "    model_dir = model_directory()\n",
        "\n",
        "    stats_list2.to_csv(f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/{model_name}/lstm_model_metrics_{model_name}.csv\", index=False)\n",
        "    return stats_list2\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "def gauss_plot(stats_list2, name, error_type, num):\n",
        "    import matplotlib.pyplot as plt\n",
        "    model_name = name\n",
        "    model_dir = model_directory()\n",
        "\n",
        "    error = error_type\n",
        "    pdf = PdfPages(f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/{model_name}/gauss_pic_{error}.pdf\")\n",
        "    fig = plt.figure()\n",
        "    \n",
        "    # define constants\n",
        "    mu = np.mean(stats_list2.iloc[:-3,num]) \n",
        "    sigma = np.sqrt(np.var(stats_list2.iloc[:-3,num]))\n",
        "    x1 = np.min(stats_list2.iloc[:-3,num])\n",
        "    x2 = np.max(stats_list2.iloc[:-3,num])\n",
        "    # print(mu)\n",
        "    # print(sigma)\n",
        "    # print(x1)\n",
        "    # print(x2)\n",
        "\n",
        "    # calculate the z-transform\n",
        "    z1 = ( x1 - mu ) / sigma\n",
        "    z2 = ( x2 - mu ) / sigma\n",
        "\n",
        "    x = np.arange(z1, z2, 0.001) # range of x in spec\n",
        "    x_all = np.arange(-10, 10, 0.001) # entire range of x, both in and out of spec\n",
        "    # mean = 0, stddev = 1, since Z-transform was calculated\n",
        "    y = norm.pdf(x,0,1)\n",
        "    y2 = norm.pdf(x_all,0,1)\n",
        "\n",
        "    # build the plot\n",
        "    fig, ax = plt.subplots(figsize=(9,6))\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    ax.plot(x_all,y2)\n",
        "\n",
        "    ax.fill_between(x,y,0, alpha=0.3, color='b')\n",
        "    ax.fill_between(x_all,y2,0, alpha=0.1)\n",
        "    ax.set_xlim([-4,4])\n",
        "    ax.set_xlabel('# of Standard Deviations Outside the Mean')\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_title(f'{model_name} {error} Std Dev')\n",
        "\n",
        "    plt.savefig('normal_curve.png', dpi=72, bbox_inches='tight');\n",
        "    plt.grid(True);\n",
        "    #plt.show()\n",
        "\n",
        "    # save the current figure\n",
        "    pdf.savefig(fig);\n",
        "    # destroy the current figure\n",
        "    plt.clf()\n",
        "\n",
        "    # close the object\n",
        "    pdf.close()\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "def prob_dist(stats_list2, name, error_type, num):    \n",
        "    model_name = name\n",
        "    model_dir = model_directory()\n",
        "\n",
        "    error = error_type\n",
        "    pdf = PdfPages(f\"/content/drive/My Drive/PhD/PhD/lstm/{model_dir}/{model_name}/prob_dist_pic_{error}.pdf\")\n",
        "    fig = plt.figure()\n",
        "\n",
        "    import seaborn as sns\n",
        "    sns.distplot(stats_list2.iloc[:-3,num], color=\"darkslategrey\");\n",
        "    plt.xlabel(\"Force [newtons]\", labelpad=14);\n",
        "    plt.ylabel(\"Probability of Occurence\", labelpad=14);\n",
        "    plt.title(f\"Probability Distribution of {error}\", fontsize=20);\n",
        "    #plt.show()\n",
        "    # save the current figure\n",
        "    pdf.savefig(fig);\n",
        "    # destroy the current figure\n",
        "    plt.clf()\n",
        "\n",
        "    # close the object\n",
        "    pdf.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2BXoG-jlHcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_runner(name):   \n",
        "    stats_df = tests(name) # Run tests on testing data and save generated plots to Google Drive\n",
        "    stats(stats_df, name) # Record stats and save to Google Drive\n",
        "    for i in range(1,4): # 1 to 3 = the colunms in the stats_list DataFrame\n",
        "        if i ==1:\n",
        "            error_type = 'MAE' # mean absolur error\n",
        "        elif i == 2:\n",
        "            error_type = 'RMSE' # root mean squared error\n",
        "        elif i == 3:\n",
        "            error_type = 'cov' # coefficient of variance\n",
        "\n",
        "        prob_dist(stats_df, name, error_type, i) # Gen prob_dist and save to GD\n",
        "        \n",
        "        gauss_plot(stats_df, name, error_type, i) # Gen Gauss plots and save to GD\n",
        "    print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSq64dXK-zO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ForcePredictor(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features, n_hidden, seq_len, n_layers=2, ignore_zero=True):\n",
        "        super(ForcePredictor, self).__init__()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device(\"cuda:0\")\n",
        "            print(\"Running on the GPU\")\n",
        "        else:\n",
        "            device = torch.device(\"cpu\")\n",
        "            print(\"Running on CPU\")\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        self.seq_len = seq_len\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "          input_size=n_features,\n",
        "          hidden_size=n_hidden,\n",
        "          num_layers=n_layers,\n",
        "          dropout=0.5)\n",
        "\n",
        "\n",
        "        self.linear1 = nn.Linear(in_features=n_hidden, out_features=256)\n",
        "        self.linear2 = nn.Linear(in_features=256, out_features=512)\n",
        "        self.linear3 = nn.Linear(in_features=512, out_features=1024)\n",
        "        self.linear4 = nn.Linear(in_features=1024, out_features=1)\n",
        "        #self.linear5 = nn.Linear(in_features=5000, out_features=1)\n",
        "        #self.linear6 = nn.Linear(in_features=10000, out_features=1)\n",
        "\n",
        "    def reset_hidden_state(self):\n",
        "        self.hidden = (\n",
        "            torch.zeros(self.n_layers, self.seq_len, self.n_hidden).to(device),\n",
        "            torch.zeros(self.n_layers, self.seq_len, self.n_hidden).to(device)\n",
        "        )\n",
        "\n",
        "    def forward(self, sequences):\n",
        "        lstm_out, self.hidden = self.lstm(sequences.view(len(sequences), self.seq_len, -1),self.hidden)\n",
        "        last_time_step = lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n",
        "        y_pred = F.leaky_relu(self.linear1(last_time_step))\n",
        "        y_pred = F.leaky_relu(self.linear2(y_pred))\n",
        "        y_pred = F.leaky_relu(self.linear3(y_pred))\n",
        "        y_pred = self.linear4(y_pred)\n",
        "        #y_pred = self.linear5(y_pred)\n",
        "        #y_pred = self.linear6(y_pred)\n",
        "\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThRgX0Yo-zPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on CPU\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "894bcCIs-zPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model):\n",
        "   \n",
        "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)#0.0007  \n",
        "    num_epochs = get_epochs() #1600 #600\n",
        "    train_hist = np.zeros(num_epochs)\n",
        "    test_hist = np.zeros(num_epochs)\n",
        "              \n",
        "    params = load_params() # model num and version num: 4_v100.\n",
        "    PATH = f\"/content/drive/My Drive/PhD/PhD/lstm/model_params{params}.pt\"     \n",
        "    checkpoint = torch.load(PATH)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    for state in optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.cuda()\n",
        "    #num_epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    \n",
        "\n",
        "    for t in range( num_epochs):\n",
        "        for j in range(len(batches)):\n",
        "            \n",
        "            train_data, train_labels, test_data, test_labels = get_batches(j)\n",
        "            #if t % 100 == 0:#100 is good so far\n",
        "            model.reset_hidden_state() # Requiered because he hiddent state was forgetting too early. \n",
        "            y_pred = model(train_data)\n",
        "            loss = loss_fn(y_pred.float(), train_labels)\n",
        "\n",
        "            if test_data is not None:\n",
        "                with torch.no_grad():\n",
        "                    y_test_pred = model(test_data)\n",
        "                    test_loss = loss_fn(y_test_pred.float(), test_labels)\n",
        "                test_hist[t] = test_loss.item()\n",
        "\n",
        "                if t % 10 == 0:  \n",
        "                    print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n",
        "            elif t % 10 == 0:\n",
        "                  print(f'Epoch {t} train loss: {loss.item()}')\n",
        "\n",
        "            train_hist[t] = loss.item()\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            model = model.to(device)\n",
        "            optimizer.step()\n",
        "            #print(model.linear4.weight.data) # Check weights are being updated.\n",
        "\n",
        "        ## Periodically save model and show training and testing loss\n",
        "        if t % 100 == 0:\n",
        "            print('Saving model', '\\n')\n",
        "            model_num = model_number()\n",
        "            model_save_name = f'model_params{model_num}_v{t}.pt'\n",
        "            torch.save({\n",
        "                'epoch': num_epochs,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss':loss,},\n",
        "                f\"/content/drive/My Drive/PhD/PhD/lstm/{model_save_name}\" \n",
        "            )\n",
        "\n",
        "            name = f'model{model_num}_v{t}'\n",
        "            test_runner(name)\n",
        "            model.train()\n",
        "            \n",
        "\n",
        "    return model.eval(), train_hist, test_hist, optimizer, t, loss_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOH4bUQb-zPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Saving Model\")\n",
        "# torch.save({\n",
        "# 'epoch': num_epochs,\n",
        "# 'model_state_dict': model.state_dict(),\n",
        "# 'optimizer_state_dict': optimizer.state_dict(),\n",
        "# 'loss': loss,\n",
        "# },\"/home/ur10pc/Desktop/robot_data2/80k_data/LSTM_params/lstm_params.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtXzj7tF-zPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/PorkPy/LSTM-Force-Predictor/master/80k_data/mean_force_data.csv'\n",
        "\n",
        "data = pd.read_csv(url)\n",
        "main_seq = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "IGY4CFZ9-zP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n=1000\n",
        "batchesx = [data[i:i + n] for i in range(0, len(data), n)]\n",
        "print(len(batchesx))\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(batchesx)\n",
        "\n",
        "########################\n",
        "# high_force_list = []\n",
        "# sub_list0 = [4,6,7,13,17,20,8,14,23,27,37,42,59,60,21,29,40,49,57,62,66,70,72,73,74]\n",
        "# sub_list = [4,6,7,13,17,20,21,29,40,49,57,62,66,70,72,73,74] \n",
        "# for i in sub_list:\n",
        "#     high_force_list.append(batchesx[i])\n",
        "#################################################\n",
        "clean_list = [2,4,5,6,8,9,13,14,15,16,18,19,22,24,26,28,30,\n",
        "              35,36,37,38,39,40,43,44,45,48,49,55,56,59,60,63,\n",
        "              65,68,73,74,78] # all traj - traj that start off high.\n",
        "\n",
        "high_force_a = [4,6,13,40,49,73,74] # large forces only\n",
        "high_force_b = [4,6,13,40,49,73,74,76,8,37,59,60] # large and medium forces # this list seems small because the testing traj have been removed. \n",
        "test_list = [67,17,20,66,76,1,41]#,10,64,33] ## the last 3 traj were removed because there was a problem getting batchesxx to work. this will have to stay as is now because the network has seen the last 3 as training data. \n",
        "\n",
        "#random.shuffle(high_force_list)\n",
        "#print(\"len clean list\",len(clean_list))\n",
        "#print(\"high force b\",len(high_force_b))\n",
        "#print(len(clean_list)-len(high_force_b))\n",
        "\n",
        "clean_data = [batchesx[i] for i in clean_list if i not in test_list] # take the good traj from batchesx and populate clean data.\n",
        "for i in high_force_b:\n",
        "    clean_data.append(batchesx[i]) # append the high force traj from clean_list again to even data.\n",
        "\n",
        "test_data = []\n",
        "for i in test_list:\n",
        "    test_data.append(batchesx[i])\n",
        "\n",
        "## drop test dat from batchesx\n",
        "#batchesxx = [batchesx[i] for i in range(79) if i not in test_list]\n",
        "\n",
        "## clean_data len = 64\n",
        "batches = clean_data #high_force_list[:20]\n",
        "val_batches = clean_data #high_force_list[:20] \n",
        "test_batches = test_data #high_force_list#[7:14]\n",
        "print(len(batches), len(val_batches), len(test_batches))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2HCaDVaLlI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.plot(test_data[-5].iloc[:,-1].reset_index(drop=True))\n",
        "# plt.plot(batchesxx[13].iloc[:,-1].reset_index(drop=True))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WabAxpcY-zP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_batch(batch_number):\n",
        "    \n",
        "    seq_size = get_seq_length()\n",
        "\n",
        "    X_test = []\n",
        "\n",
        "    data = test_batches[batch_number].reset_index(drop=True)\n",
        "    data= data[:seq_size]\n",
        "\n",
        "    features = data[['joint_0', 'joint_2', 'joint_4', 'joint_5']]\n",
        "    features = np.asarray(features)\n",
        "\n",
        "    targets = data.iloc[:,-1]\n",
        "    targets = np.asarray(targets)\n",
        "    targets = targets.reshape(-1,1)\n",
        "    \n",
        "    for i in range(len(features)):           \n",
        "   \n",
        "        X =(features[:i+1])\n",
        "        an_array = np.array(X)\n",
        "        shape = np.shape(X)\n",
        "        temp = np.zeros((seq_size, 4))\n",
        "        temp[(seq_size-shape[0]):,:shape[1]] = an_array\n",
        "        X_test.append(temp)\n",
        "        y_test = targets\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    force_scaler = np.asarray(y_test)\n",
        "    force_scaler = force_scaler.reshape(-1,1)\n",
        "    scaler = scaler.fit(force_scaler)    \n",
        "    #y_test = scaler.transform(y_test)\n",
        "   \n",
        "    \n",
        "    X_test = torch.cuda.FloatTensor(X_test)\n",
        "    #y_test = torch.cuda.FloatTensor(y_test)\n",
        "    #print(data, '\\n')\n",
        "    #print( X_test.shape, y_test.shape)\n",
        "    jim = targets\n",
        "    return(X_test, y_test, jim, scaler)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nehzUS3F-zQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(batch_num):  \n",
        "    \n",
        "    seq_size = get_seq_length() # 1000 = full trajectories\n",
        "\n",
        "    # random.seed(batch_num)\n",
        "    # random.shuffle(batches) # ive turned this off to test new cleaned data\n",
        "\n",
        "    # Randomise the fetching of new data to break the corrolation of training.\n",
        "    #print(batch_num)\n",
        "    #print(type(batches[batch_num])) \n",
        "    data = batches[batch_num].reset_index(drop=True)\n",
        "    data= data[:seq_size]\n",
        "    ################################################\n",
        "\n",
        "    X_train = []\n",
        "    X_test = []\n",
        "    \n",
        "    features = data[['joint_0', 'joint_2', 'joint_4', 'joint_5']]\n",
        "    features = np.asarray(features)\n",
        "\n",
        "    targets = data.iloc[:,-1]\n",
        "    targets = np.asarray(targets)\n",
        "    targets = targets.reshape(-1,1)\n",
        "\n",
        "    for i in range(len(features)):           \n",
        "        \n",
        "        np.random.seed(42)\n",
        "       \n",
        "        X =(features[:i+1])\n",
        "        an_array = np.array(X)\n",
        "        shape = np.shape(X)\n",
        "        temp = np.zeros((seq_size, 4))\n",
        "        temp[(seq_size-shape[0]):,:shape[1]] = an_array\n",
        "        X_train.append(temp)\n",
        "        y_train = targets\n",
        "    \n",
        "    ###############################\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    force_scaler = np.asarray(y_train)\n",
        "    force_scaler = force_scaler.reshape(-1,1)\n",
        "    scaler = scaler.fit(force_scaler)    \n",
        "    y_train = scaler.transform(y_train)\n",
        "    \n",
        "    ################################\n",
        "    data = val_batches[batch_num].reset_index(drop=True)\n",
        "    data= data[:seq_size]\n",
        "\n",
        "    features = data[['joint_0', 'joint_2', 'joint_4', 'joint_5']]\n",
        "    features = np.asarray(features)\n",
        "\n",
        "    targets = data.iloc[:,-1]\n",
        "    targets = np.asarray(targets)\n",
        "    targets = targets.reshape(-1,1)\n",
        "    \n",
        "    for i in range(len(features)):           \n",
        "   \n",
        "        X =(features[:i+1])\n",
        "        an_array = np.array(X)\n",
        "        shape = np.shape(X)\n",
        "        temp = np.zeros((seq_size, 4))\n",
        "        temp[(seq_size-shape[0]):,:shape[1]] = an_array\n",
        "        X_test.append(temp)\n",
        "        y_test = targets\n",
        "\n",
        " #############################################\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    force_scaler = np.asarray(y_test)\n",
        "    force_scaler = force_scaler.reshape(-1,1)\n",
        "    scaler = scaler.fit(force_scaler)    \n",
        "    y_test = scaler.transform(y_test)\n",
        "\n",
        "###############################################\n",
        "\n",
        "    X_train = torch.cuda.FloatTensor(X_train) # Change data to tensors\n",
        "    y_train = torch.cuda.FloatTensor(y_train)\n",
        "    X_test = torch.cuda.FloatTensor(X_test)\n",
        "    y_test = torch.cuda.FloatTensor(y_test)\n",
        "    \n",
        "    #del targets, features, data, temp, an_array\n",
        "    \n",
        "    #print(data)\n",
        "    #print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "    return(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thk1hwULis6G",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cv2RZ52m-zQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "seq_length = get_seq_length() # when using zero padding, this seq_length is a bit redundent but still has to match the zero's size.\n",
        "\n",
        "model = ForcePredictor(\n",
        "      n_features=4, \n",
        "      n_hidden= 64, #32, #64\n",
        "      seq_len=seq_length, \n",
        "      n_layers=2\n",
        "    )\n",
        "\n",
        "model, train_hist, test_hist, optimizer, epochs, loss = train_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3KahlpCLy8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_save_name = 'ForcePredictor2.pt'\n",
        "# path = F\"/content/gdrive/My Drive/PhD/PhD/lstm/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JQbLodYJ40g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Saving model\")\n",
        "model_num = model_number()\n",
        "model_save_name = f'model_params{model_num}_vlast.pt'\n",
        "torch.save({\n",
        "   # 'epoch': epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss':loss,},\n",
        "    f\"/content/drive/My Drive/PhD/PhD/lstm/{model_save_name}\" \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "u9wQYHgS-zQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_hist, label=\"Training loss\")\n",
        "plt.plot(test_hist, label=\"Test loss\")\n",
        "#plt.ylim((0, 5))\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnwajR7M-zQO",
        "colab_type": "text"
      },
      "source": [
        "RL Controller Predictor"
      ]
    }
  ]
}